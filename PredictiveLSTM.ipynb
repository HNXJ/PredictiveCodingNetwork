{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PredictiveLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyObV9XxVhHxy6ERRYzT/n4K",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HNXJ/PredictiveCodingNetwork/blob/main/PredictiveLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx1wIbKYUJZv",
        "outputId": "72f1349b-bdda-4051-fb7e-0304d4825a8c"
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# GPU config if needed\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzeiPBSWSqzf"
      },
      "source": [
        "# Recurrent neural network based on predictive coding properties\n",
        "\n",
        "In this simulation, we will use task of [Abdullahi et. al 2020] by increasing temporal resolution from one image per step to 10 iterations for each input."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9gapZk0XZd5"
      },
      "source": [
        "# TB\n",
        "# dir(tf.keras.layers.LSTM)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqPCOuRhVWR6"
      },
      "source": [
        "def create_serial_dataset(x=None, y=None, n=100, length=10, frames=10):\n",
        "\n",
        "    X = np.zeros([n, length*frames, x.shape[1], x.shape[2]])\n",
        "    Y = np.zeros([n, length*frames, 10])\n",
        "\n",
        "    for i in range(n):\n",
        "\n",
        "        k = np.random.randint(0, 1000, size=(length))\n",
        "        for j in range(length):\n",
        "          \n",
        "            X[i, j*frames:j*frames+frames, :, :] = x[k[j], :, :]\n",
        "            Y[i, j*frames:j*frames+frames, y[k[j]]] = 1\n",
        "          \n",
        "    return X.reshape(n, length*frames, x.shape[1] * x.shape[2]), Y\n",
        "\n",
        "def init_MNIST():\n",
        "\n",
        "    (x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\n",
        "    Xn, Yn = create_serial_dataset(x_train, y_train, n=100, length=10, frames=10)\n",
        "    Xn /= 255.0\n",
        "    Yn /= 255.0\n",
        "    X = Xn[:10, :, :]\n",
        "    Y = Yn[:10, :, :]\n",
        "    return X, Y, Xn, Yn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIUZqCsgYKio"
      },
      "source": [
        "class RNNModel1(tf.keras.Model):\n",
        "    def __init__(self):\n",
        "        super(RNNModel1, self).__init__()\n",
        "        self.Input = (tf.keras.layers.InputLayer(input_shape=(None, 784)))\n",
        "        self.LSTM = tf.keras.layers.LSTM(input_shape=(None, 784),\n",
        "          units=512,\n",
        "          recurrent_dropout=0.2,\n",
        "          return_sequences=True,\n",
        "          # return_state=True\n",
        "        )\n",
        "        self.FCN = tf.keras.layers.Dense(units=10)\n",
        "        return \n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.Input(x)\n",
        "        out = self.LSTM(x)\n",
        "        out = self.FCN(out)\n",
        "        return out\n",
        "\n",
        "    def get_state(self):\n",
        "        return"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ro8ZWDSeKqR"
      },
      "source": [
        "class PredictiveNet():\n",
        "    def __init__(self):\n",
        "        self.model = tf.keras.Sequential()\n",
        "        self.model.add(tf.keras.layers.InputLayer(input_shape=(None, 784)))\n",
        "        self.model.add(tf.keras.layers.LSTM(\n",
        "          units=512,\n",
        "          recurrent_dropout=0.2,\n",
        "          return_sequences=True,\n",
        "          # return_state=True\n",
        "        ))\n",
        "        self.model.add(tf.keras.layers.Dense(units=10))\n",
        "        self.lastPreactivation = None\n",
        "        return\n",
        "\n",
        "    def printw(self): # Debug log\n",
        "        print(K.mean(self.model.layers[1].weights[0]))\n",
        "        return\n",
        "\n",
        "    def getPreactivation(self, x):\n",
        "        MTemp = K.function([self.model.layers[0].input],\n",
        "                                  [self.model.layers[1].input])\n",
        "        stateVector = MTemp(x)\n",
        "        self.lastPreactivation = stateVector[0]\n",
        "        return self.lastPreactivation\n",
        "\n",
        "    def EnergyCostLoss(self, y_true, y_pred):\n",
        "        error = y_pred - y_true\n",
        "        lambda1 = 1.2\n",
        "        lambda2 = 0.0\n",
        "        lambda3 = 0.0\n",
        "        # preact = self.lastPreactivation\n",
        "        return K.mean(K.square(error) + lambda1*K.mean(K.abs(y_pred))) + lambda2*K.mean(K.abs(self.model.layers[0].weights[0])) + lambda3*K.mean(K.abs(self.model.layers[1].weights[0]))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5iTIYNPGZCOp",
        "outputId": "bfdadcfc-58bb-4362-8cd5-a31bfe28fabd"
      },
      "source": [
        "X, Y, Xn, Yn = init_MNIST()\n",
        "Net1 = PredictiveNet()\n",
        "# a = model.predict(Xn[1:2, :, :])\n",
        "Net1.model.compile(\n",
        "  loss=Net1.EnergyCostLoss,\n",
        "  optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        ")\n",
        "Net1.model.summary()\n",
        "\n",
        "Net1.printw()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, None, 512)         2656256   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 10)          5130      \n",
            "=================================================================\n",
            "Total params: 2,661,386\n",
            "Trainable params: 2,661,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "tf.Tensor(0.0013962194, shape=(), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HE5dIE-Yw4L9"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PEdkEmGKfF5"
      },
      "source": [
        "means1 = []\n",
        "means1a = []\n",
        "\n",
        "for k in range(10):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "        # plt.plot(l_pred[0][0, :, i])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means1.append(np.mean(np.mean(l_pred)))\n",
        "    means1a.append(np.mean(np.mean(np.abs(l_pred))))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBnTEiUpKfGW"
      },
      "source": [
        "means2 = []\n",
        "means2a = []\n",
        "\n",
        "for k in range(10, 30):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "    #     plt.plot(l_pred[0, i, :])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means2.append(np.mean(np.mean(l_pred)))\n",
        "    means2a.append(np.mean(np.mean(np.abs(l_pred))))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ISJediqKfGX",
        "outputId": "60353225-2844-4602-e604-fd6495c0a7c5"
      },
      "source": [
        "print(\"Mean energy on recurrent preactivation (LSTM) on sigmoid activation function before training\")\n",
        "print(np.mean(means1), np.mean(means2), \"(ME)\")\n",
        "print(np.mean(means1a), np.mean(means2a), \"(MAE)\")\n",
        "print(100*np.abs(np.mean(means1)-np.mean(means2))/np.mean(means1), \"(Difference ratio, percentage %)\")\n",
        "print(100*np.abs(np.mean(means1a)-np.mean(means2a))/np.mean(means1a), \"(Difference abs ratio, percentage %)\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean energy on recurrent preactivation (LSTM) on sigmoid activation function before training\n",
            "-0.00020369247 1.669759e-05 (ME)\n",
            "0.14919743 0.14980337 (MAE)\n",
            "-108.19745328498233 (Difference ratio, percentage %)\n",
            "0.40613355146132774 (Difference abs ratio, percentage %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIqr5QqRVBEw",
        "outputId": "e6fbcffa-ec5f-4ee8-8588-29d55fd53979"
      },
      "source": [
        "history = Net1.model.fit(\n",
        "    x=X, y=Y,\n",
        "    epochs=100,\n",
        "    batch_size=5,\n",
        "    validation_split=0.0,\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "2/2 [==============================] - 3s 346ms/step - loss: 0.9948\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 1s 298ms/step - loss: 0.4441\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.3157\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 0.2704\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1357\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0832\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.1026\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0917\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 1s 297ms/step - loss: 0.0605\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0416\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0342\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0415\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0358\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0268\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0203\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0224\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0218\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0164\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0140\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0139\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0145\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0117\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0098\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0101\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0089\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0080\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 1s 300ms/step - loss: 0.0080\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0073\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 1s 297ms/step - loss: 0.0072\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0069\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0071\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0076\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0070\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0067\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 1s 299ms/step - loss: 0.0066\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 1s 296ms/step - loss: 0.0067\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0083\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 1s 297ms/step - loss: 0.0084\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0076\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0075\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0069\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0083\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0078\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 0.0079\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0066\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0060\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0061\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0068\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 0.0060\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0061\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0065\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0071\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0067\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0068\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0066\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0064\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0061\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0056\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0067\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0068\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0056\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0058\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0051\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0050\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0051\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0056\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0054\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0059\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0051\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0052\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0048\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0051\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0051\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0051\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0046\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0049\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0060\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0059\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0054\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0050\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0057\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0056\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0052\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0051\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0050\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0050\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0050\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0049\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0045\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0052\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0059\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 0.0052\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0049\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0056\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0050\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0048\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0049\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0049\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0049\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0042\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAzs21WYVFtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afda7d22-27b2-403e-bad2-ee93985677ce"
      },
      "source": [
        "# Single epoch for test\n",
        "history = Net1.model.fit(\n",
        "    x=X, y=Y,\n",
        "    epochs=1,\n",
        "    batch_size=5,\n",
        "    validation_split=0.0,\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")\n",
        "# history2 = L1.fit(x=X, y=Y, epochs=1, batch_size=5, validation_split=0.0, verbose=1, shuffle=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0039\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "1dMlf8hTlL1b",
        "outputId": "59e16b20-d232-4896-ee01-84766e7f9963"
      },
      "source": [
        "# for i in range(100):\n",
        "Pa = Net1.getPreactivation(Xn[8:9, :, :])\n",
        "plt.plot(Pa[0, 20, :])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f029efda790>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO2deZgcVbn/v2/1NksyySQZkpCQDcISdgghiLIGiIqiiAoXFb1grutPn+sGyhVFvcJFAfXigqjgyiJ6QURCCPuaBQJZICEJCdnXySSZycx0d53fH1Wn6tSpU9XV3dXTPd3n8zzzTHd1LaeqzjnveZfzHmKMQaPRaDSNi1HtAmg0Go2mumhBoNFoNA2OFgQajUbT4GhBoNFoNA2OFgQajUbT4CSrXYBSGDVqFJs0aVK1i6HRaDSDisWLF+9kjHXI2welIJg0aRIWLVpU7WJoNBrNoIKI1qu2a9OQRqPRNDhaEGg0Gk2DowWBRqPRNDhaEGg0Gk2DowWBRqPRNDhaEGg0Gk2DowWBRqPRNDhaEGg0mppm1/4+PLJsS7WLUddoQVAFnlu9E8+v2VntYmg0g4J/v2sRPvPHl9HVk612UeqWQTmzeLBz+R0vAQDW3fDeKpdEo6l93t7VDQDImWaVS1K/aI1Ao9FoGhwtCDQajabB0YJAo9FoGhwtCDQazaCAiKpdhLpFCwKNRlPTMP6fsdD9NKWjBYFGoxkUaDFQObQg0Gg0gwJTawQVQwsCjUYzONByoGJoQaDRaAYFphYEFUMLAo1GU9Nwi5A2DVUOLQg0Gs2gQIuByqEFgUajGRSY2jZUMbQg0Gg0mgZHCwKNRjMo0D6CyqEFgUajqWn4jGJtGaocWhBoNJpBgU4xUTm0INBoNIMCrRFUDi0INJoapbsvh017DlS7GDWElgSVIhZBQESziWglEa0moqsVv59BRC8TUY6ILpF+u4KI3rT/roijPJrC7Nrfhz+8uL7axdCEcMkvX8DpNzxe7WLUDFojqBxlr1lMRAkAtwE4D8BGAAuJ6EHG2Apht7cBfBLAV6VjRwC4DsB0WOJ+sX1sZ7nl0oTz5XuW4Jk3d+LUySNw+Oih1S6ORsHrW/ZWuwg1hY4aqhxxaAQzAKxmjK1ljPUDuBvAReIOjLF1jLHXAMirT18AYB5jbLfd+c8DMDuGMmkKsGt/PwCgP6cXBNcMDrQcqBxxCIJxADYI3zfa2yp9rEajaQB4/681gsoxaJzFRDSHiBYR0aIdO3ZUuzgajWaA0XKgcsQhCDYBOET4Pt7eFuuxjLHbGWPTGWPTOzo6SiqoRlOPrN2xHz9+dGXdx9nX+e1VlTgEwUIAU4loMhGlAVwK4MGIx84FcD4RtRNRO4Dz7W0ajcamUAf/id8uwM8eX41te/sGqETVQZuGKkfZgoAxlgPwBVgd+OsA7mWMLSei64no/QBARKcQ0UYAHwbwKyJabh+7G8D3YAmThQCut7dpNBqbfIG4yUZx+GsxUDnKDh8FAMbYwwAelrZ9W/i8EJbZR3XsbwH8No5yaDT1SM5kSCaCfycauLJUBb0wTcUZNM5ijaZR0R2ghX4MlUMLAo2mxilkGmoU6t0ZXk20IGhQ6t6cMAB88OfP4R+vbq74dczGcAEURMvDyqEFQYPCB1d6kFUajDG88vYefPEvr1T8WvmIL4nVuTu10hpBNm82rPalBUGDo+3PpTGQHUbUa9Xrq3RnFlf2OlO/9S988OfPVfYiNYoWBA2OFgSlEXWUHsu1IvaA9f4uB0LjeW1jV8WvUYtoQdCgcB9Bg2rCZTOQdvvIpqE6f5f1fn/VRAuCAaZWIh9cH0FtlGewMZCjb7OAtOZFqXeNoN7vr5poQTDA1FpdblTnWLnUpmmowgWpMrXWduoJLQgGmFqpy5UyDeXyZkNoGYVG6XESVejU64iZ16d6vb9aQAuCAabWKnPcnfZh3/oXvvn3ZbGesxapzaih2qpbcVPfd1ddtCAYYGpNEMTZn/Vm8wCAvyx4O76T1ijaNDTw1LugqyZaEAwwtVaX4+zQ9vRkAQBNqfqvVgMaNRSxh693f4/qmTPGsGF3z8AXps6o/xZbY9SaIIiioVx2+4s48fpHC+63u9taB3lYc6rscpUDYwzv+9mzeHjplopdYyA1gqhaZK1pm3Gwac8B57Pq7u5euAHv+p8nsHh958AVqg7RgiCAJRv24P3/+6xj7oiLWmusUdTtF9buQqc92g9jT09tCIK+nImlm7qwatu+il1jQJ3FBa7FHf81VrXKZv7r23D6DY+ju99qg6q2s2idJQDW7Ng/oGWrN7QgCOA7Dy7Haxu7sGLL3ljPK1bmWrB5cnV71s1P4Qt/frmsc+22BcHw5nS5xSqLbN66qUo+Xt45D0TyvkbVCJZu8s7yVd0en22scyiWhxYEAbijrHgbl3i2Wmi33MSxevt+PPRaeaYUrjW0VVkjyOate6rk4x1I01AuH3VC2QAUZgAhqXuX2+LrW/Y6q7NRDafT7c+ZuOFfb2B/X67aRQkklhXK6hHDrlhxNy4mOLxqod3GKeg6bR9BW3N1qxXvHCqpcel5BJVH7tvFR752x368+yfPDGyBSuS+xRvwy6fWIJc3ce2F06pdHCVaIwjA4BOuYm7wYmOthYYb5+11HbA0gkSVR2cDYRoayNF31AilWjA1xolci8Skc6u2DR6fANfo+mp4bWktCAKgCmkEXh9BvOcuhTiFUc7ugKttoujngqCCOpfjI6jYFYRrRdYIKlyQCrFmx35MuvqfeH7NTs/2MI1g295e776VKlwMOGbmmrABqNGCIABjAHwEqk744aVb8MOHX4/1mjKbhZC8OGPPeYdV7ZEpNw1VsmOspaRzxe5Xa7y4dhcA4B+ven1Ust1frFdbuiRBUKYkqGSd5UWrhYFfEFoQBMB9BHG/u0IdyOf+9DJ+9fTamK/qsmTDHrzjhsexfLMVDRVn5eRCZSAdqSriNg39dfFGXyjqQE7eytX5zOKo74mFaQRlCoLB+uziQguCAHjFitIIe7P5yBEBYmWuho9grRRvHWcZeOdY7UaVjdk09NX7XsX5tzzt2caFXVzRKqbJ8MZWdahyo+Ya8puG3PuTBUG5VLQtVmhQGSdaEEh09+XQ059zNIJsBAfPOT96EsdcNzfS+avtI0gY3tYVZ6fNhWa1TRSOU66SpqGY7/FXT6/F7FufwZINe/zXqnMfQRCGzzTkfuaz2DlyqGmxiMI2boEal2no9qfXVGwGtRYEEkdfNxcnXj/PGenlIoRsbO6KPjqptkbgEwQx9h6moxFU2zRU+XLE7SxeZk+eUuXNqfRSlV09Wfz22beqolEwxpxoMxn52Yr3t0ea6Z4zGbojaOU/nf8mlm/2L0fpbZcFT1MUcQXR/ffDb+BDv3g+npNJaEGgoC9nOs7i/gKTeaLCGMOdz73lqfRhZ65Uo0z6NIIYo4YGQBDs3N9XcFTkziMo/3pBgrKQHyRvsqKErGHwKDX/MZWeWfzNvy/F9Q+twKKQ59qXy1ckZccvnlqDm+auBODvMOXv4t119ng1gq/e9yqOLqCVM8Zw87xVeN/PnvX9Jr5PblqMn9pV2WIRBEQ0m4hWEtFqIrpa8XuGiO6xf3+JiCbZ2ycR0QEiWmL//TKO8sRBMaahKLz01m585x8rcO3/ubn6WcipozoIN3b2FJVnJWF4X3mcox/eEVWsHQG46H+fc0ZFT6zc7nT6Iq6PoHyCOnyuKAaN9g795sO4+BfP4w8vrMPWCBojF9Cq0X8hjYD/Wqrg27G/D0D4DOZr/74M59/yNHba+8bFo8u3Bf4WNLO4N5svKSafP0bV4xSFaNS2FxV+H7XswilbEBBRAsBtAN4NYBqAy4hInj53JYBOxthhAG4BcKPw2xrG2An232fKLU9cGI6zOJ5ejSevE22bYc7MqKOSd974BM798VORy1FRjYCndqhgjefZKBeu241P/W4hfvToSt8+WWc+Q/nlCOoco0RGLdmwB//1wHJc9fuFBfc1HFOk/7xRO6ZSI5n4ccmEX6ot29SFSVf/E/ct3ggA2Ncbb5qEMLNJ0DyCXZJ/QCSs7oXVB3FQlo/JCsCJIylgpf1ucWgEMwCsZoytZYz1A7gbwEXSPhcBuMv+/FcA51ItJwcBwC2UcZmG+O2KjTXs3WZz5V+3uy+HjZ1em3NYJEa5OBrBAAx9du6zRqbrdnb7fuuL0TQUNBAo5rnJ9mwVCYPv2+/rzAp1AvyVlvouuaCRnbOAG+PPiVPIL9vUhVfe9jvHg+CX3hWilYQ9qjBB6TENxbzYhOMsLkNHjbtMMnEIgnEANgjfN9rblPswxnIAugCMtH+bTESvENFTRPSuoIsQ0RwiWkREi3bs2BFDscPhA+e4TEOqxhrWcPvy5ae//rc7XsI7b3zCs02+ZDEjjUL7uj6CyKcsGX4JVecVp403qPMIehbrd/kFU5QhD3fi//fDb+BPL3lXeKv0zOK83cnIgQSAv77E+WovVNjqReSxIm8vcsSQSFhnH9bexN/iniMSh0ZQKPFguVTbWbwFwATG2IkA/hPAn4moTbUjY+x2xth0xtj0jo6OihfMKCJqqBjEyhBWMbIFXvydz72FYws4x15VhCLKZoZi6nwUBykwMOGjvCiqTjYbY9K5ILOMGzXkFuCJldtx5k1P4qHXNnv2jRLaKAq0J97Y7vkt6vMs9X653FR1gHLnOZCRRf5cQxZha4SEdfahQkL4LW5nseMjKOMcg0EQbAJwiPB9vL1NuQ8RJQEMA7CLMdbHGNsFAIyxxQDWADg8hjKVDW+XhTrkYs8XNV65kCbynX+swL4S0trKjaEYc0KhkZI7oSzaOaM4UYPg11AJgv4Ycx4FagSKe1y60QpLfGOLN7pGMdD2IY7G5ZFwpdcs5hqBWhB4v8ftSBUJCxcF3PYS5igO1wiCry3+FnunG4NGMBhMQwsBTCWiyUSUBnApgAelfR4EcIX9+RIAjzPGGBF12M5mENEUAFMBVC6/QhHwtqiKSgnjkl88r1zWkY8KtgozIsPqRaVC2OTGVYwgKLRvMYLgqVU7MPOH8zF3+dbI11ddSzXadtcjqKRG4N/G60oq4W1WUdxhoiCQBUf0FBPl+QhU2q98zkqPTEV8gxb7e182uG2EPaswzUrUduOPGrIopz7WvEZg2/y/AGAugNcB3MsYW05E1xPR++3dfgNgJBGthmUC4iGmZwB4jYiWwHIif4YxtrvcMsUBbxPFmoYWre+MtKwjEN5w+0MEQTmmF79GUPqxQb9HeWR8ApVqJi3nn69twYrNxaddiHMeQVAEidNxCJ02f2fppCwICl9HTN0t+z0qPY+AP0tVZyPXtbB6GTeyKZJ/68uFmIYidPaq9yEeF7c52BkIlKMRVPi5x7KCCGPsYQAPS9u+LXzuBfBhxXH3A7g/jjKUwhtb92LqQUOVTjJeacJMQ2t3lLeqV7E+gs7ufry6cQ+OHTes5GuqNILo2S3Df+fPLEqH5C78E7zv5+2lM9fd8F7/tUx/R8yJ0zQUGDWkODkXQD5BEOE6Ho1AGp5F7QNKFXxcAEQyDQ2gRiA/Y/61N8s1L/K1kzA/lmNODPkNiP8eXY2gdCppkgOq7yyuGtv39eI9P3kG81aoJ7TwRhFmGvrXsq24ed6qSNdTVdCwTlA1Apjzh0X45O8WhkZNqBB9ESp1+++vyC4dNVGdxVGiXIwy7ab5kEbt+lfKbzxBmocqxQQXQBmfRhDBWWx4NQLxnRUSrCzifkE4GkEEZ3EuQCpFSe9QfLm8310fgaURNKcSvmPCBjVhAxnxsPsWbQidONebzWP9rm48t3pn4D5xE/Tc46JhBUFPXx4mA7oOqDvVMLsppxh1La84T6hGoBBAa3dYoYnd/cWFlorXkRt7T38eX7nv1Ujnie4sLnwu3jeWauYKi33vjzENdaCPQHHyII2gs7sfn/79osCcOoDXNJQwyPOsK+0s5veorKPSd5Vp6LEV23D0dXPxytvlJUSTX6XPNGR/5Slg0km/IAgbhIRljBWf8V0vrMdVdy0KPM9pP5yPM296Epff8VLgPirKibiKK2gliIYVBHykIzZ009P4rAofNrGrGEeySt0MqxeqBscrcLEObM/cBam3KEbljOosjlLhy10Tmt+HMnw0RkFQaB6BeH3XWewt1K7ufsxbsQ33LPTODxCRNQJPFEuFncW8ris1Arm+KOrxk6uscNfXNvqTuRVDoTkupqMRmMgkE0goeq8oIaIq/Uyus/JETBHRBxhFSPNyl2ca0hpBReAvJZdnWL19P1Zv3+9pCLzCh436o2gEpsnQnzOVjTQ8xYT/N17xD4TEUasQR0nyiKkYe2hUjSBK4+BCLegZFBImYZ1jfy66r6IQQe9YNfLkJguVlhK2HfCm/iAKF95BlDridLRflbNYri+KDom/b5WvrRyCnMW92TwyKUO5NrZpAvcu3KA0VYXOMZB+izoCjzIo46cuK3xUawSVgTeabN7ErJufwqybn/JUcl65sxGiU8K45m9Lcfi1/wqwvwYfp+qAeMU/0F+cPVasgHKnUpx5Kz7TkOwj6M3mPY23UMXn5VZ1Pf1xJp0LnEegKlNwhwr48zyJJHwagXuOqO8oynO/7YnV+PYDyzzbwn0E3u+qlCv8fmVNqFh86U+CNIKsiUzS8GhRnBff2oWv3/8a/ku6R0Dw6yijhrzfo9rkwyKYnHPHoRFoH0Fl4O1MbOhi58MbRdjErih5iO5ZtMF3HbcMYRqB/7q84nf3FacRhE2f/8OL60s6jwonaihCjyRHDV1w69OeNMKFOj8uhFX23mysuYbCTUOqMgWp8QmVLYP/Js0jEN9TVA1w+eYu/Oe9S0LTRd80dyV+/8J6T90L9REonMVPrdqBLoV5RM5sWy5yXXV9BHk0pRJKDeuA7T/bssc/WdGNGlJoErJGEFELi5IFlZ+KP8tNew44kw+joqOGKgR/ruID9iaEK2wakjWCsOgclfYgv1vxeNX+vLPoKdI0JF6nHA2zkEbAR4bRwkfh2Xf9Lq9NtpAg4CMxZdSQ4yNQl+Otnd3YsS9aOuXCUUOEeSu24dbHVjnvLEibUZkyOOIvso+gJ2JwwB9ffBt/e3lTYCSciHj/ZqhG4N22fV8frvjtAnzuz4udbTlHEEQqZiByB+13Fos+AkNpiuKbooTCen/zC7wo8MlteZM5c2OCzs2v8Lk/Lsb7/vfZopbbrPQ8goYVBNw2LT7gnOez9XvYBBr55YgVTf5NPfKW7a9q7YTDR0A9RYbqeSNQSq9QhTp4/nsUQUAFnMWFJi45gjJkHkFQKc7+0ZOYfat3DeLuvpxScARqBMK+n/79Itz62Jvoy3NBoC57mGlIvAoReTSOA0VGie0NiU7iLBcm6rkagf9e5VvhkU/rdrqCm2tA5Wpgsr/I5zx2NALLWax8nHwdkRBfhopSJ1r228khb563Ehf+7FnlutNOXRHKDwD/eHWzb98gan5m8WCF1xOxAqi0gzDVTx61i+e64V9vYP7r7shMFVERNlmnX2F75BW/WGexV1Mp6lAPhY4tJvsoF2pBo/ZCPgLHNKSQBO7MYv85uCYh5rTfvrcXR183F7959i3f/kGCU2VvdkxDAWUPm04gChZDchb3FPAJyacNC1Md3pICoF78XfXMZaHOhZK4doEzaIopUy9H7pxfemsXHl66xXIWJw2laYgP5sR3MP/1bdi850DoJMRSLS98chtPp71jXx+6erL4wwvrnPonmxE7hmYAeE28yzZ1YbO91oYKHTVUIVyNQBAEHh+B9eDDBIFfI3CPv/P5dbgyJBYZ8I94xFGMOmqIO4tLNw2VE0lTyDRUzJrF7jwC9e+Fku7xUX9Y+KiquBs7/Y1trb2mgSrvUTEL03DhHZQgLOz5iacj8p4/qmmIEyYIuFbCBxNiJk9R6C1e34m/LHjbJ0y5UBLzKTmBFWWaLwqZhp5bvQuf+9PLlkaQUpuGeMcsDuquvGsR3vvTZ9yMtbCElhicUGq74P2DGDn1xbtfwX89sByrt++3z23tK1sheoXB3oU/exbvuOHxwOvoqKEKwd+7xxykiBrqCxl9y+aLYiuTvL+Y10ZlGuEjoG7FCDF0RmWI76IYCt1fmIkh6FxB4aOFfQSlRQ29bS8OL/YhvEMYkvFnXOH3Ivc5SmcxNw0FzD0Jc0B6ZxJ7BUMhDVA+a9hCOLzz5B3mFiEDrNh53r3gbfxo7kqfMOVCSTRz5SJoz6UQVKf7cnnbNKQSBFb5ZBt/Z08Wf13sLpvy0dtf8AQnlDqxkWuYvD4niBxfQdIWlnK74c8+LHmeTKU1glhyDQ02bn96jRPh4Jk7oPgcpu7KvxVbl/yRCn4fhYjjLFaMEPOMwQjIahOXIODHLtvUhSdXbscXzpnqvY4zoazwuVztQf17IR8BHyGp1yPg5fCffIMtCDqGZrBhdw+eWrUDQ5usZtCqEAS8HvhTQ1v/xXdRKGooTMvxOPTzzPOe4tQIeOfJhcsWwRwhDkR6+vPoz5k+Qb3fFpri7GlXI4h31BpUV/uyJppShi8nE+AKI5Vv564XLD8dEXwro5W6qp6sERgGOSlgck7QAjz/+TG9EUJPOVojqAD//fAb+N5DKwB4G63Y+UbxEcij1mI7Wbnuea6vqJiOIFCEj4rX/sivXsAfBee02C+VJQjsMl34s2fxo0f9OZZcHwHD9n29oeGxhVJWF/YR5O3zqI4N1gh4I21NJ3HxL57Htf+3DJ3CtqByyvImLMVEkBDLmSYWvLUbk67+p2+JTTkNiPhcVKZAxljg8w0TBI5ZwhYEmwM0gp7+HPrypu/57rfXLBY1gmwBJ3lUZKET1Dn32hqBKgrL0QgcB7b/HCq/UhQ50HUg64sM4u+cV1fxGWSlKDpHENhl5BpBlImAuZCBTxw0nCCQG5XKLwC4LzHUWSxV/GJndoYJApWq6kQNKUwFYsex4K3duPb/lil/K2c9YblMslDh37d09WLGD+Zj+vcfw8sB+Wf4rQYVJ+o8ApUzty/EWcwXX+/LmU4IZdcBa1u4RuDdrno//NxBfoVsnuEvC6w0E4vWe5+LV2szHeHdkk74TEN5k2HyNQ/jlsfeVF4nTBDw58bbgeigFOt/t60R8PJyuEaQFHwEvB2U6yyWH2mQuaanL4/mdEI5oYybatxQ5mjXjjJA+tLdr/iW1+R1zVRoRfx5yj4CWSMQ+5Gr7lqkDEPl56qQHGg8QbC7x5tkLihkk484w2YOyrbgYgfb8gjIYxpSCgLrv2pmcVien1LSFaiQG4tsApGFzK7uflz88+eV5wpyLDszviM6i1V9bliuoX29VicpOkn32IkHWzMJdPflnH0AV70v5MgExFQNAaahvOl0pEMyVsK07Xt78YnfLvCsyyBqBK2ZpC9qiHe4P52vFgT7+3IhZbDOy4VLZ08/hmSSSCcNT50LCkjg5RdnEfN9w4T3xs4efPEvr6A3m8cbW/fi0ttf8O3jG2gEVNU9B7Job0kF+Ai8czmipnZR7cfvZ39fDj+au1LZQfdl89jXm3Ucw2K9coMWvBpBr6MRcIe9+9wee30bvv7X1xRlUZso46LhfASdUgpnscGIIxre0RSjERRrdpF3V01oEwnzEfBDtyiWfxRPVbz5yt2/uz+HXzy5Rnkuxlikc/fnTPTnTWHtAu/veZMhmSDn2QaF3rsTefzvJyz7KB+1i6Ns7lw1iHDKDx5DT3/eWQPB6RylcixeH5xpM2jGeS7PHNPKkEwK9y7agN89tw6vb/HGnudN5jyfoZkkduzrg2kyZwQsDhiCtNDu/jyGNbvjvJVb9+HZ1Tudzonfv2kyJAxCkpHkI1CHrPKoKzFqiJ8rzK/znQdX4LHXt+HC48bizufW4cW1/vWnglYkU+3X3pIONQ3lTW8n7N3HX07Vftv29mJ8ewt+NHcl7nx+nbIsfTkTH/nVi84zEGdcOyvlSRPKHEHANQNJ42tK+cfnuQLtoVwaTxBIGoEYySG+EMfemzPBGFNK4rCZxVGQ9xdHVKpO1XH0qQSBybCxswfvvPEJ32+eCWVFllE89sZ/rcRKIX2BJ3NrwGnl/DMfu+MlLFi3G1+74Aj7OFnLYEgm3EaUtD2Cnd39+Onj7giYdzpL3t6Dzu5+tLemnd+4NqFq3CpBwOcU5E3mE7IqH8HCdbux4K3ghfSiaATJBClHfoD1DJigEfDy8s+i6UmOEMokDfTlTPT05zCsOYX9fTnc/tQa/PTx1Z79+hxbOkPSIJiMImkEnKTgqeXtRmwPnd39WLerGydOaAfg1oO8LXhUhA2MZIa3pMOdxU4nHHobTttW+ffX7ujG+PYW7O0NNrX15UyPIBf7F9k85XMWK0J4AaBJsc6CY6KskHGo8UxDkkYgjoLEzkGsg0EjHZ9GUHT4qPd7VuGsFgkLH80zFpg2oRTTkGkyXPfAMryx1e34N3d5Y/DzAf4VET5yfGzFNmzf24sF66wO1OnMfM/A63jkjf3xN7bjd8+tc/bjnc7mrl58VDIzuGsW+9lnd8Tiq9rd3WffQ7C5RzRD7CyQniLIRJLNM0cQhC6paDLHSctDWh9/Y7uwpKToyzI998InjHGBdsu8VT4hAAgaAbM0jVTC8EYqFQhZTScJi9btxiPLtgipNUys3r4Ps25+Cp+8cyE++PPnnU6Ud/7ZvKm07fOyeJ5DSHsKNg1553IUCnkOMyGt2WGZe1S+jwuOHq38bY/gn8ma1iDSPTdDLm/6wm1lDUW14I6TZFFrBOXDGMMvn1rr2SZ2YPJokI+uug5ksXp7J2ZMGuFxkoWlmIhYIs830Tatqph8m9I0ZDI0p/0VCLA6s9ueWI2PnzYxUvKqZZu6sLc3i7teWI+5y93Z0Xw0LZ4XAOb8fhHOOuIg5blSCQP9ORNX/X4Rjhwz1NnOV4DyNX5pcpKjEUianNgAV23b73xmjPlMQ8+v2YkfP7oKd8+Z6XnGHG6uUT1zbmIQG6D8HGSC5gvkTFcjCAsJzZnMuX/esX/xL69g854D+I8zD/Wc3/rsfm9vSWPb3j4nsixoDgIf8edNZplYDKktFEhsmDQMXPJLSwBzYfX3VzZhx74+x0WdOBkAACAASURBVF4OAIvXdeLsIw9yBgS5PENQktKopiHA0ghUmoWsERSq7jnTRBqG792nk4azEJRKEPDOeos0OBI1tL6sicnXuCv4msxran5tYxfe2LrXJwiUGkHI4CYOGkoQbOnq9dljswEaAWBFbPTlTNy3aCNumrsSF580Djd/5ATnd988gjJ8BIwxj7Yid9jX/t9SvGSbI4LmEaQCsn499Opm/PTx1di5vy/SpDcxMiJ0xSe7jI+u2IZHAxKdpRKGMyoUI1T4Z/k++fvgz5a39V2SJrdWCr+Uj7ewPn/tvtewac8BbNnTq+zEndmoqhTLCo1gR8gyhtZ5QkxD9vXDzA2m6QqzEYLJi3dM3pxYpqcDHdZsCQ6uNQYNIA8IM3ATBoGYe/+5vFlwHoeYYkJMtvfEyh0ArBF7Z08WC9btxtlHHuR02jnTDDENxacRmIyhL5cvaOLKBgiMMW1Nzuhe9SwShoF0wsA6KVmiuOKhnMYjbzKfGWj2rc/g7jkzPdsygo+Am674wKCc8O8wGso0pOxARXVYSuY2tMlqVFttB+wjy7Y6nX13Xy40xUQUxN3/+NLb+NLdS9xz2de5e8HbmHT1P/HHF90wPnVyMBZoD91kp+QlUKwVSWUOSkvCKJ0gJ5yxNZPEqCFWx8bj1+VOk5+TN1DeaezeH22dZvGduLZZ68O+viz29WadXC+cA5KDUYSbv8Qup1Dm0qA5ENk8c64VlBiurSmJnGk6netIQRA4zmLh/Nk883RirmnIFgQBkqBXchYnDEJ3fw479/cFmoXamtxxo2irVneU1u9v2toa9xHkTLW/DXDbDzfJhNXV9pa00nHqCgLg8l+/hFN+8FjgOQDrPfzgnyt876MlnXD8KMqU8GRpDduk4AxRI9gk5Q6yhJP/XEE+glsfW4XJ1zyMvMmc9pI3g+ePlENDCQL+wKeManW2iS/5h/96w7N/W7NV8blZoqc/jxVb9uL5NTtx9HVzfQ2++Kghd/8HhAXkh2SSzrm+/cDySOf63kMr8NBr6myG3AwzojVVdNK5sDqnqpSyczidNJxGZgkCqxMO0gjkleH4DHA57FfFrv19Hv+JXLaHXtuC3qyJgyRB4ESahISE8vO9vasHdz6/Dh1DM7j4pHHKcgT7CNztKs0knTRwzLhheHHtbrxlazwjh7hl5R2fZxKk6V39rr3FEhx80KMaNRskmIaY1WknDcLDS7di+vcfCxxFX3j8wZ7rhsE7xHW7rPvgJj7HFKXANIHnV+/EuT9+Cvct2gCTMYwb3qzcd2hTMjTXEOCdq/F+oewiP5n/Jn79zFvOuiEcbhYG1KYhgwgG+TVVURDIy10uXLdbmetKFgT8rvik0PW7urF2h2tuq4RS0FCCgM8J4KMmIHzBh6EZaz/RPr2xswfPvrlTuX/R8wiE/UX7fltT0umUCqnonLnLt+HWgAlGu2xnaGsmCZOxsleS4li2bEkQSAu3pxKGqxGkE86z59vkTtNZEMgRBNZ22cnvvQaBMYaTv/8YvvjnV5zt8uvgoa+yIJDTBACuRsa37evL4YybnsAjy7cAsLSCoAlUQYJAND0FmYZ453bN35YC8JqGHPOKlChRrEfDuEbQF7xeQ1tzypnMlLdNNaLvS7XMI+CdTRyWzwhw3+Pbu3o8kULZfHDUUJ4xZxT9wppdyJuWIHjg86d7UloA1oQ2lZALmvczfVK7cjufv8EFKCeTTDjnUgoCw9LQZN/VHk9f4e30e7MmPvIr//wJ2UfA68+UUUMAACu27HXMgkBlzEMNJQj4AxcbV6ggsFXhzm630ncdyAbOLSjeNOTuL0YKpJJGWRO/ZHbusypn1o5YaFGkUlCVCQiPUsgLTk2O7KdIJw3s7Q2ZuZv3ahXcVOTOI7BNQyGCIGkYjsnlJSGs02TWIjSbJfX99MNGKc0KYqrwf7vjRfxlwdue+rFh9wFH8P32k9MDBUHwzGJ3/70HFJ0t82tgomnIOb9nEqRXIxjebO3v+AgUL3B4cwp7erKYdPU/sbHzABJEnk4+yJEtduBRF1Xpz5vY1HnANQ3lzcA6ZdrzAwBLAzRNq8M9/pDhaFEEQigFQUAit6D1orljW+5cMylLI1i9fR+6Fc/DIMs4Jh8nRg2pRv8yQzJJn0bA69jEkS0AgKdX7cCBbN7RjrQgKBP+wIcL0l+2UZ84YbjzmfsI9vT0O7btrgNZ34vjmCx4tKNCfJ1iRU+QFdOtcjqOaWuKfH4O1wj6cyZMk6E1ILoIKC65VS7vFwSyjyCVcE1DLemkrxJnJa2Cf+aztnkD3hXioE0apDS1MMbwPiklAGAJ+KXfuQC/+vjJnu3iYi0vrt2Na/621Dc63tPTj+ZUAuccOTpQWwuKGvIIAoVGwOB3Jo4Y4tZVbrLxZsxlkmnIDR/t7svhze3+ZSsPO2iI83nZpi4Yto/AuU5A/U4ahPceOxaAtVJZVB5dsdWT5DHMWcxH/p3d/VYiRfJrQRylaShAIwgSBBz5njPJBDZ2HsCsm5/2REGJ5+NCVmxPohAtpMUCVl2Ury2nWOfaAPdtlZMmJogGEwR2SF6zYBqSKhjv/K3P3EeQxaghGSQMsgVBgEZghq9CxeFhlGIDFlVzw7AWL1c57VoywZ14EGIkTj4kzBTwN4iwOpczTb9pSGF2cp3FCYVPwBv14i6k7jaGbN50tAoVyQQpw0IBNyWCSDppoDWT9JmIVPC01eK98MicQNNQwHYxjYRqXWHGFJFrKVeL4qN8eQ0N8ZG2ZizbeU9/Dp//88t4bvUu33WmjW1zPpvMqrNhGgEfmSYMA7ddfhKOHDM00HwkMmFEC44Z14ZHV2xz6kU2bwb6CPLMff+7e/o9JiWVT0I1HyFoICPvKn+XBXAmZTi+taDz8XMMb0njb597R+C+Mh88cRxu+agVfTi6rcnXn8hLnnIto82ud/kiBmtRiUUQENFsIlpJRKuJ6GrF7xkiusf+/SUimiT8do29fSURXRBHeYLgL9szC1Ua1Q0VzBf8wfNZnW1NSds0FKwRRDEP/eCDxwCwJP1X73sVPf05TweQICu6Jyx+uRT67NQOqYSBH3/4eDzz9bN9+wRpOypyCtNQUtIIcqbpmVQkC95cnnkX5DHdsEbA6hy5HTZoUJdMGAEaATClo9W3PZ2wnmFQuK2ILAj29GQdP0egaSjAkdop2NXX7PCHvzL4BUEq6d70/j5vZk3+WTStpZMGWtIJdPfl8ZIijQMAHCkIAsDqUEUTkixUecfNhUXCIJ82dNMlx/misZIGYeLIVk+Hms2bwVFDppumpLM7C1ZAIygm3YKsEcix+q5z3fqeSRqhgyDrHqydh7ekcNKEdieqanRb+ADDIMKFxx2M0w8biaRBvno0b8U2PPPmDucZc78DP39NagRElABwG4B3A5gG4DIimibtdiWATsbYYQBuAXCjfew0AJcCOBrAbAA/t89XEbjaKC5AItv7xd/EcLmWdALDmlPoOpAL1ggYK+gwfv362U5D+PmTq/HXxRvxu+fWeUJXDYOQN9UdjcpWGhVuGkoYhA+dPB6HjGjx7SOPBsMSial8BDxPSntLCqOGpJHNMccenjeZf96Aafqcn9Z/14HLVWx5BM/bdirANGQyhjZbw+MpLQA3l34ygtNcjvzYcyDrDBDGtasjWsrJHS/buEVh9fSqHbj09hc870jWCNJJA63pJLr7coFBAQcNzeDgYa6JMUHA0Qe7wkH2X/DnnBAEgdwXDW1KIiM5dBMGYURLGp3d/e5s2qwZuMi9ydz6sb8vhzwTNQKFaaiIabbyrrIg4Ga3x79yFpZ8+zxkkuHtzDINWZ95+nJerw4fPTToMPtY63/CsBL98XWPRT7+mwVO++eOeV7vKrFITRwawQwAqxljaxlj/QDuBnCRtM9FAO6yP/8VwLlk9YYXAbibMdbHGHsLwGr7fBWBd+CiacQnCITOXxQKriAI1ggWress6MhpTiecSI5te62R0jNv7kBPv+UMWvDNc+3cL2qNoFAFDaM/Z3oalwo52VjYerkqHwHXWCaMbMVph45CNm+6qYEVfo+Nuw9gU6c/FTLvTPNMFARe/wjvjBIJUpqAGLMa+Oyjx+CyGROc7Y4gUCWrkcjmvSGMew9kHdPiDz54LE6bMlJxTGkNlTG/jyCVMDxJyF5cu9tjn5edxemEgXHtzVi/q8cXaSOe8/lrzsXxh1j+sKRh4LNnHer8LvsvmHOcKwhU55TrfsIgtLdYbYaby+549i3cu2ijslx5k0lmwuDwV0BtGgrCpxFIz4Y/9yFNSQxvSfuEmkzCcMvBT83r02EHDQkNsuDPL2kQlmzYg9ueWKPcz11bwXom3FRdq87icQDEINyN9jblPoyxHIAuACMjHgsAIKI5RLSIiBbt2LGjpILyB9viEQTehje0yW8aso5Joq05ha6e/kDzyfX2YjeFkCvlrv396OnPY+roITiorQmGQXj8je342l9f9R1bzprD3EcQJgiCIhhUWOYr7+98pNWcMpCys4g64Zl5f4bS/ryJB5a4cyi4RiCm1Q7SCDgpw/CbMwwCA0N3fw4tmYSnU+SNPGoY7WRh3oloGhqSSeK8aaN9+++KOPlNRmUayiQNLP3OBR6TpThAyErho0MySRw1dihe37o3UNBxLYOnwjYMYHx7C657n6XIy5OrHIFrn081EpfTWAOWxjW8JQ2Tec1iQTDmHe1a2qt/P95+ijINSefxaQT2c+f3llFkAJXLwCfVyZFtUzqGIBUyyDCMYIEqIqe95tptrQqCAYExdjtjbDpjbHpHR0dJ5+jL5kEENAmjannULWoBolBoTifQ1pzCqxu7sHBdcApiGdVEFrkd7eruR09/zlExef+kuk6UXEFB9NuO2TCVuphlES1nsTpPypBMEinDQDbvzpLNmV5/wHjbtCKG3PVm83hgySbnvDv39+OehdZY4aAA2ysRcMs87xyKdMKAyaz7aU0nPdFMrmkoWvUfL5iA9hzod5zF/NoyvFO5+t1HOttOEqLRZMT+QKURpBIGrnrXFGebOHiRzQodQzM4amwb9vXmsH2fOsQzneQdkd2x8xGq/TzkhW34u+CaiWoknhY0Aq4VJojQ3mo9qzDHKycvpTLvy+WVnWWhjlT1TuTBl6wtyRPwCmneJJiG+H9u0z90VGuo2VH2uQQhC0/HWVyjgmATgEOE7+Ptbcp9iCgJYBiAXRGPjY3enIlM0vBUINk0JHb+YgRRazqBT75jUtHXVDl35UrZ2dOPfb05x2QVNlIIymPjPb96O9cIwlTqQrlZRNQ+AuseWjNJpJKEbJ4JE7ZMT8RDOmEgaZAnAuU3z76FL929xDPT8xl7Al/HELUgWLOjG1uluPZMygCYNTmqJZPwjP65UEhFGFKmk4Zn3klv1vSYisLCEi87ZQJOsScyfejk8YH78Q6YMf+kRF4XvjRrKm665DgA3sGLLABHDklj8khLgwnqL1LS/XOBwL/v7XX9C6OGZJzrNQkdvO+cSVcQcEFpmYasZ1coLQfg9yFt3tOrXD6UXz/I6TxEcUwhZzGHd+CqNQG853PPKRdjSseQ0E4+EVEjECFyNbhaFQQLAUwloslElIbl/H1Q2udBAFfYny8B8DizQh0eBHCpHVU0GcBUAAtiKJOS3mweTalEqP1OFT4KAM3pJE6ZNCLQ7hqEqGJe9c7Jvt/bW1JgzIrL5vHIYZ1LlErAG7pY1qGZpOUsZuEaQVAMuYqckByNw80urZkkUgkDPf05xxFuaQRu+Q2DkEkaHvs+d4zJFrBUgpApImIqkzSQMy2zVGs66ek0XNNQ4Xd5SHuzL0pjomAqmqnwEfBrtDUnnc44zFQgz70IgndS4uBFjmrKJBOeOqyC3zc/H5eRXCDtPZDF0KYUbrj4WNz/2dMcYc+fm6oDEzUCbjpLGoYjCKJoBPLiRv15E+PbrYAGcf6M42wNqMeiSdc9RhYE/mfOI66AwhqBeD753KPbMqF1i+8fpf5xWlIJjBqSwQmHDC/quKiUfUbb5v8FAHMBvA7gXsbYciK6nojeb+/2GwAjiWg1gP8EcLV97HIA9wJYAeARAJ9njEXviYqkN5tHUzIR2tGKs19b00mn0vFOWnYyFUIceVx7oWWDFa8vhtw12yOZMLUyimnIEQRChWnNJF3TUIwagRzWx/vMIRnLHNObNZ2cLznJR5DLm2hKJTyCoCkgKornw4lKJmmFUAL+SKtioobGDmv2LUk6aaQrCI4YMxR//vSpvuO+MftIa8ET+4GormU4HbD7W1joIa83hdYGFgcwKlxBIJmGHI0gi+ZUApfOmICJI1udd8zrskqjzARoBCPtCXFRJqDlmT+q7JARlvZ1hJDCnF9fteQkoL5/uciqjn5Ua9oZMAQ5i/mzskJulbuAiEI7a/5TWDtsk+6hJZPEu6Z24P8+f7oy2q9cYhEtjLGHGWOHM8YOZYz9wN72bcbYg/bnXsbYhxljhzHGZjDG1grH/sA+7gjG2L/iKE8QvVkTTSl1jhKObEvmFYZ3JkEqpcgHTnD9AirBIV5ejISJohHk8gx3fGI6Pn/2oYH78AomagQt6QSeeXMnXn57T7ggKHMeAf/emk76GgM3JfHr92YtU51oGmoJeL4JooKq9MwpI5zPaUHTkFNbpIvQCIa3pDz3mDDIlwhN5ZTlReX9mnIUrSjHA59/J35++UnKsvB6EbaONqDuCP9wpRuMJ5vGXB+B9X9fb84jPPtljUDxGtIKQZBMEMa0NTnnzyQNfH32Ef6Dbbr78nh6lTcQhHd6l81wLcj8fMo0HVDfv2xGUnX04izuIEHATWaiaYj//+XHTnJmq4cNMgxJ8KoYLWUQCMsGEAeDxlkcB73ZPDJJtWno+PHDcObhHZ4Gm0kaTmPlo/UoguDY8cOdcDyVKUns6EcJlY9X4FAfgWli1rTRnnBIGV5ZRbu4GG0UNmIUncXic5p99BifOp1XOIsdQZBJ+BpDzrQ0kuHCRL2mlDtyB/xJ6zgJwz/KeuTL7/J8FxOHiSYnn0bAR8SK53zte4/ynVOMZBnalPS9U5U84e+QT/ZSCZ20QnMbM6wJ5xypXuQnSCM4wo5b574MlWlIDIKQneWuRuA6i8Vnxkfpjo8gKHyUeU1DBlnJ7LhZZ3RbU2A2UcDKCzVPWteCO+pnHzMWf7rqVOe8QHDiPtX9y0UW2zF/biNaXW0syAzJn5E4j4D/n33MWFxw9BgA6pxbPP0HN2mFtXM5MCIsP1gcNJYgyFkagUoQXD5zIu769xmeRm1pBLbN224YUcwJBrlOXVUHIF5fzHvEK3CYDZ+PusIqEa+s4rXFxFli9lUZMWpF7Fg/eNI4PPHVszz7fvNvy3DjIys927ggsJJpeTss7gwcJgiCtOQj6A8Y7fKc+SJHjmnDe48bK9yXVxC4WU/VGoHqGcodVVtz0hMiqxr9JxTb+AiUvy+V0Ekn1XUq2Cxh/ZcDHC6bcQgWXTsLT33tLPu8huccv/zYSZ5yywMF12bNR9pZT8fD7yHUR5A08JHp1qid12N+z3ziXcL2CRWD6BvgHTYvrxzdxBmiSG4Y5iPggzExwV9QOZOCRsDPqNLgVe/bad9RNAJpzozqnuKkoQTBTz56An79ienKF5eQ1DzAelHc2etMQovgsE8Y5FtYRcTwCAK3U+aT2cKieripIcx8xCurONIUZy7LKXdFRI1AzMlkEPkE1IFs3smbz+m377s1k/Ss1gS4E8qGCSkaMqmEZw5AUGZXSyMIb3DtwrMUR+3HjR/mOYb/poo6kX0ULemkxyGuarwqwc3fu+MsThi+zoV/l88ZFA1DARpBx9AmjBqSkQIdrM8XnzQOs48Z65SHyB+1wq/PNYS+nKmcwR6mEaSTBr7/gWOw7LsX+ATGeI8gKM7EIT4L0SwDBAsCpY8gZB4B99ONCBAE33yPGwbMBSoRuVFDijLIA8Bc3nQnwjkaQXD32yFrBCXkGCuGhhIE7a1pa8KWaraiwoFD5FZcbmeOErhF5K4EptIIxOur5i0EaQSj2zK444rp9jWCr6+KGhI1gmGKqAqO6CMQhVTCCO6gRPi5R7SmlfHoJvNevylpeMIcg5zVCYPUAtwjCNyGzEfb7zl2DA6S7K1hUTpydE9TKuFJIqfqBMOEPROcxfd/9h2eyDF+XNQokESAIBihSFXNnY28w0sm3Gvx9+iYOXg5hPtQJSbknaP4Hg4fbWUyTSessOwhmaTP5MQ72mSRGsG/neo1fyaleQ+yj8Ax4yrMOnLdFQUB11xHCeHJY4QUHJ8W5nCI+Za4BFA1C3nQYjK3DO57D25Pcqi0Kow2ThpqzWKOasAtO344mZDKBQDPX30OtnT14kO/eN7ZxtNIA4U7DvF6fCEcefbw6LYMtu3tw/cuOsbJYxJmPkoW6GCGh2gEYkcsdqzWCCjwMIfvX3QMTp4wHO84dCRue2K15zc+2hcFgWyLDXJWJ0gtCMTRtNgh8u2qY8IEmtw4m1MJj49AZRpUCwLZNGStPjZtbBvuePYtz3FRQ5K5jOrPm0gabh1TCXY+qJBH56IQdFJGcMEg/BZFI0gYhD9/eiYWr+/0dKxcoPDHzCdwElHBGbucJd8+z5lJy5HbqDybvDmVQH/OVD5Pub2IAmmxHdU2Y7K7eM0EITJHrC9JhbNYVZ/CtPqweQSnTRmJoU1JXwK/cnKMRaGhNAKO6sXxl8JHwWcebs1e5pWKvwh54ZaOoRmf/c4gd4WrpEH42gVHeBaoFjsnsTLwxitHiB5lZ4sUTRThpiHuI1DvMzxMIxA1hxbJNFRAEqQTBoa1pPDJ0yeDiDwzawE3oZqsEYgELoqSIJ96D7jqdTppeEwCYfbbMGRndXPawNXvdh3IStNQiCCQw0fFDsIxyUQMi3WihrKmRyANU/h8uGmIa7RJxSiU1xN+LvGcKuekGzXkdmSjhmQcB6l8Xi4/eRsyTRZoGjpFWkFseEva15nyZ8nrwZ8/fSo+PnOi8zsfrKmuETahjPuFjh/vzv4Ocs7ywRVfmAZQm4bCBmq8LKr3fuYRHbj9E9N996Ba1ClOtEZgw1/c+PYWLPzWLMeBJE6QUpE0/CNlwyB89YIjkM2buOiEcT4126sRuNu5j0AWNmdM7cCTK3d4FgwPG3GoNII/XnkqPvablzzXUdET4Cw2qLBpSB6JHTd+OL52wRG4aa7lUObZX4eHaAQ9AXnugzQC3rE12WsMcPiuxczeBLwj5hMnDMf508agNZPEZ886FL94ck2AszhYOPA3GSZAopqGHEGQN5EyDPTCL1g5XDuSNQLxWnzkruqYVCPQjDSPIEiA8XfCO25ehqxpBpqGJo5sLZi6hZ+Pt9WTJ47AyRNH4A/22r6Ob0wZqef9zoXGN99zJN53/MHo7M5GSjnC71lMMaFOjBemEfD//utNstd+SCe9x7dW2EfQoIIgXJUT1TIumXlnLvsIiMjXKRtE6Biawc324hNh1xePHRqQb/xTp0/CxJEtOPsIN6wwrH9TNYh3Th2Fkye2Y/H6ztBKekDINio+hyhx/KpGLh7DI5LEmZ/iMa3phHIxHn6eME2uOZ2QBIHXPBGEQV4NTOwo7/zUDOecYSF/qg6Rv1czxFcUZhp68qtn+d4T378vm/eM3lUx5nwVMp49VhVJJnd8opBTCgJJIwgWBNZ+/LFyAZI3WWD4dZQ4+QkjWnDetNH4/NmHhV43k7QSHooJE+W6k0oQ1t3wXuf72GH+sNafXHoCtu/1ToRLOhpBcIoJwNVaMknDFwDhCF7hHU4Z1YofXnwsTrVnqsv1pdLho1oQ2ASpcrzy84lOquSf/gZb4PrC7+KxXOjIpiEiwrlHebNchnXm3OEpO0Vv/NBxuGXeKhx/iBtF86GTxuP+l920wAeyeUzpaMU17z7Kk+0zio+gkG2WO+VELcBJZEaWpqJaHxbgzmL/dt4ZNaUSTi4WwFXXC+Wsb00nsU/QQkTTiSikwhKdqbQzvom/S5VvIcw0NGmUf0Edfiv9edPTiasEJHfirtq231Nu8R3JWot4781hpiHHlBQeYsnbCj8ul2eBGsEXz52K9tY0bn3sTeXv/Hq//sT04N+Fe0wlDGSFhHzyIw6L2OFcdII/EXJSUQ9UVUwcoMiCIMhHcKqQrkQWBHpCWQUIe3EyaXtSmZMYTBE3JHc2hezS4v4JIkyRGr1sGlKeQyqv2MCDVOTDDhqC2y4/yWN//PFHjsfzV5/j+CF6+vNoTiVw3rTRHseeOAISESuoUiUvMIJ2Z24nQyfrGQGmId6gm1OyRuAex7n/s6fhtn/zztqVw/LEBigKUie8OKJGwPcXncX+spdoGsqaBRPmnTZlFADgcjvyxukkFc5i5gircI3AiXopMCGKD0SYZBrKh/gIRg3JYNZR/pTexZAUNAL5ncjvrZh0JSJuGC4JWmewaUjMdMyfhyMIhOPkFs/TmHCndYueRxA/hUxDIplkoqDHXj5dQUEgjSb+/vnT8fTXzna2RVlzQL6EGJboOoujvd6DhzfjM2daIXK9/XllUjYjIHzzkS+fgbF2qJ0qLFPV4MRtXCNoSiU8jcZ3TKKwRuARBDxXvHDQyRNHeCagAer0E3xNafFYfmuqN6vKj887Byd8NMxHEDFqyDEN5fIFI42GtaSw7ob34nzbkctH8eLSl0mpwy7kI/CVO6DNOBqB/Z13/jmThUYNFZvQUSYlDIDkc/k1gtIEgTfFhLVNdSZRI5Dh9UUcVMqDvzHDmrD0O+fjP+x2qcNHK4Ay+iSg8z7t0JGeBqLqo+VKVUgQeDsYwrDmlMfhx6Mt3nPsmMBl78RrrLvhvdi85wB+/qS10hFvoMVkKeTn42kfAG/HLlZ8kUNGtOCCo8fgzufXRdcIEoQvnH0YJo5swZYuK310JmmEdhIJCvcRNKUMT54id15I4CkB+BtYKmHgnjmn+bJ6CZY1swAAGuBJREFUGs5I0H8O0YEIadTnOIuVSefCO1T//tb/A/350EmBKlQBBLJTV/wtbG1sZ0JUQFSaEzXENQL7veZMM3wOR4lZNZ/9xtnI5hm+cu8S63rJhO9cct2JkiFAhSrFRJizWGUKcyPK3G2qod/QppTzvPSEsgoQNqFM5pKTx+NGOw88AGca/VfOO9xJhFWsj0AUOqqy8AZ00Qnj8OVZhxc8h3VN8n2WIw/CEAUBr7xix96cSgaOokTbrMwIRYdFsKKqPjz9EKfDYYyFagTiTE7VtZtTCa/dXFo9Kgg5GiOVIAxrSeFYaTay09krzmEofuOPKsw0lCpSc+P30mvHyg/NJDFj0ogCR1mozFDiOgjWd/cORE3pjk9Mx1fOc+shP0XQCmhp2UdgH5DPu2thTBjR4iRo40RdMU5mfHsLJo9qlZzFskZAePwrZ4bOL4mCN8VE8OCAn1/UCNwJZdZ3cVA5UjEpEHDbVKVTTDSmRqB4cVEXwv7iOYdhzhlTPPbsoHS4wdcXBIGiMLyChDUMubjid1WKicJlsv5bGVoT9vXd44c2JZUjckA9WYnznmPH4H8+dBxe2dCJvyywFpsRk4WNHW6ZlXZ19+NQO9JFBVGACm7fqy+EMmS0JqLSCFSEzttQaAtO1BBPCaI4rROGGbEDFCeppZMGln73gkjHWWX0BxD40mAIhRQ7sFnTRmOWsCRnofBRx+Rkf3c1AmvLvf9xGiaPavWtoFa+acgNlZWfaYIIUzqG4IzDO/D4G9tL9hGIgsQIqWP8MasGN/Ick2HNKfzyYyf79gPc+hmWDSAOGlIjCDMxRDlWdmrK+eoLLSLmjRry/65S1VXlEBEFGR+pFKNqqxducbfJszwBOIuf82cX5GD8yCmHeNYh6BKW4Js4wnKK9eWCY8w5YSY9OeNk0ExxGdlHEPTMEiEjSceBKM7zkBp7mDYTdXQq1tFihLx1Deu/+E75Jz6Q8U4oC/ERFHAWu1FD3FnsXVlrxuQR6Bia8d13sfcUdF2VCYpfSnbYFktCMA3xkyoHKCE+Avna/3bqBF8aFM6ZR3TgN1dMDzQRx0WDagQq01BpFQPwJ7kq5OyVo4ZknNmoEULcOMrJVkWMsMTbd3wEwvHyJLSH/9+7MKXD6sTDKj1HzEQqCtIJI92p/IVWIFMJcB6a19bsLR/fs1Dfwt/dVe+cjDHDmgI7iIRi1M/hz37awW1YsmGPtb+9bUxbE3Z39ytXKAsTLirE3YodPRNZC/t4AgCc3tFbHgBoSQV3DYWinRxnqBw+aqrj6TnlrrzF20s2z5SmISA8nDcKjl/AEARASJ1QafVyivKwrieVMHyh45WgQQWBf1tU05CK9tY0Fl07C9c9uBz/fG1LYUHgiRpSCQLrfzE2U48gc0Z/pQkSxzQkdF5yBzlqaNpdsUoRKifDJ5Odc+RB+OTpk5ztwwImlxUqI4fnm+Eay/2ffQeaUgZuf3pt4DEiXz3/CORNhq+cf0SoIHMzTfrPl04auGfOTBw5pg3HX/+ovb/1252fOgUvrN2lTAMRJS+9Z/8yNALAqiPi4IC/XpUGKiZdCypHULFlbShofox8fLmC4OiD2/DY69swakja13bkey3VR8CPKmwaCn63slBS1amBpkEFQemmoSBGDck40R+F1hUWO3/Vdc0S1FeFHHCcdpGOF9qgk2Uy5Pqi4OQmjrCon1575P7x0yb6GvwPLz4WE0a04J9Lt4SW8bhxw3zbeAZKPlv55IlWzhqnwRZ4hu2tadzwoeNC9wGEdxFwulOltYv5dQ9qa1JOTAJc/0bUPkmst6XY05MGeQQI74BUq6iFnb/Q4vH8NI5GEFAvVLN9y+H/nTvVnkE/wjfZTW7zUTLpquCHeeYRKPYLM026GgHft6SixEqD+gj820odIXjOEVEQeK/r31aKIFBpGcV0FmLD2N3dH7Kn/3r8vsNGqVwjUGkNl82YgNMPG1VQI2hvTTtpAc46wkoKuFfSCJwySZOfysX1A0QjSn0q1kdQriBIyILAaxkCAHz3/Udj7pfPCC9HiJnM+sH6x+txUL2Qq3epnTMnYRBOsaOo5GvKwqnczteKGuKfg0f9Yb85loOY6mg5aI2Ab4tBJPJOJ8J8MOG6/rK4lbUYjUAQBLw8JfoYNncdKLi/2GiNCILHEQQhWkPURUuWfud8xyw10Z6BOXGktKC3o7ZHOmVB3FFwxP0jPHp3gZKogsD9XIppSJ6r4euQAFzxjkkFz1Mo4oZrGnLUkEwcg68g5pwxBc+u3umWKYLzvhjEme6qU/HXozRDS3NMtEZQJYrJNVTKeeWkccWWhWsUxRTJIwjsj8Vo2mJl/O77jym4v9h58WU5wwQBT3UwWZFDhxMmJESGNqUc89J/nnc4/vqZ03CMwmwElBcEIKKKDAqjmI4munBxdywmEIBz04ePx6dOn+y/bnHRz2i3Y97F6C8R+bxBQquSA+EzDu/wJJWThV6p1/a8f8FMJBMeZWZ/iEkoxUGDagT+bVFS0BY8bwmmIZUAKk0jcD87GkEJzuIjxwx1MleGIZabr5OQTgSP6D96ygR89JQJgb8DpZk70kkD01WTqkp4hmEUNIfI+0fYkRXZEXhMQyXUVzF7LSCO3IuTBHzpya17e5W/+9diGHiNQCbhlMn6XqqD1g1DddtZmKlZFBLy+77qjCnY0tWLTwnBE9WiIQWBSoK3heTojwqv71FyBXEq4SPgFDNphl9TXtj+7597h2cJP474CPnSieVOCCo3jlyEv4FygwA4xZuGinh3UQWBcM5iF4FXno/b8gvMe5E5pN0ywwUtIsTTl584Ybhn+2hpHd6BHAjL8whKrRauX4UJkWR+XLMf8MuPnYS2phS++fel9jbrt7amFG768PGlFSRmGlIQqCqBPCGpFE6a0I4/vvh2pBG1UxZFYY4c24Y3t+8valq5ymZfjLlrX68VfSPPYDxxQrtqd09H1xeTIBCjiTqGZvCjDx+Pzu5+fPmeJUWP31iZJgAZ1+Yb7YRRduPvLGqn5PERxCAIeBmLGbgA4aGlgGX+e+TL78KhHW47uP+zpzkChDOQGgFvZ462HcMAwZlTUMA0NPsYb6LDuAIY4qRBBYH/RcTRsC4+aTymTxzhmSRVSllu/NCx+NipE3DwcP9iGZFwbJfRD9lj23uHN0dLZqY0DcUkCIiAhd+aBQD4x6ubARRtxnZDImOLGiru3ooK/Y06j0C4l3Jj7gEhQ2qRx/Frh2nRR45p83w/eaLffDeggkASenEoiqEL04SE2Mblt4qThhQElax/xQgBQB1d0pJO+uLSg5g5Jdg+Xkw43kh7ac5jxqudrjJiZeamoUyZnZOcHx8o3bTjRmTEJQiK27/UiK8wxPcZx8Bl5uSROGhoBl8IWPErjPlfOdM3o75YVK/2njkzY9HO/deSfASlziOAW0fDNQL+m/8ccZkr46SsN0lEIwDcA2ASgHUAPsIY8y08SkRXALjW/vp9xthd9vYnAYwFwOMVz2eMbS+nTFEoN145Tsopy6rvv1tZqXgnWMyZz582GnfPmYlTJ0fLZikSm48gJGVvqaahuEZfYYuQqCjV0R9GuTOLZYa1pLDA1ryKRTT7lIrqWUYdABV/Leu/YzIs+UT2eQrsFrqiXQ31P5xya9PVAOYzxqYCmG9/92ALi+sAnApgBoDriEg0PF/OGDvB/qu4EABqI26XU47pIp001IKgBPs4EWHmlJElCSZehLAVxqKgyq1UapZI5piGyimReELrX9TTRSk2n/x02EHREorF7SOoNgPZDg3JDFZsZ/yTS0/Ad943zU3Ux1xncVg4eiWyGFSCck1DFwE4y/58F4AnAXxD2ucCAPMYY7sBgIjmAZgN4C9lXrtkakkiV6IsTupj+9wfPFGd4iAu/uvCaTiorQmzjjqo8M4hhCXoKhYeEhmXRlCsbTlKuS+bcQjOPKIj+sI0EVNADBYGUjPnbeGoMW14bWNX0WmdeZqQRetdgwcvfriPwP9bPTqLRzPGeIKYrQBUafLGAdggfN9ob+P8jojyAO6HZTZSal1ENAfAHACYMCE8Hr0QNSUIKtCeHdMQAat/8O6K3+/IIRl88z1HlX0e1SSpUjvyUuZiRDlfnKYhIsK44c3Ysa+v6HPGGWpbLQZWI7D+f/eio/Hh6eMxKWRiY1RI+u+5XsiEskq0+XIpKAiI6DEAYxQ/fUv8whhjRFRsAMLljLFNRDQUliD4OIDfq3ZkjN0O4HYAmD59erHX8VBDcqAinbQoS+OYKDdQRF3zOAqxCwL7f2TTUJlzQJT7xewsrjYDqhHYz7gplVBPQIyIKkxb9a7DRv21NBDlFBQEjLFAbxIRbSOisYyxLUQ0FoDKxr8JrvkIAMbDMiGBMbbJ/r+PiP4My4egFARxIr6Ir88+IvJyf5WgEvbCuCNmBgpVSGSp9+BOyiurSCVTzGuNuq/4KLRGUOy1YgoasP+LUUOqM6uWo3SXqqy9dllubXoQwBX25ysAPKDYZy6A84mo3XYSnw9gLhEliWgUABBRCsCFAJaVWZ5IiO/hc2cdVtYIIc6yxEXck6kGinh9BBZxjTrdZ1r86L0QpZib6kEjqMY8gnIRZxZzERA2V0CVvqMWB2jl+ghuAHAvEV0JYD2AjwAAEU0H8BnG2FWMsd1E9D0AC+1jrre3tcISCCkACQCPAfh1meWJRC29iMqYhqz/tbDgRTGoNYLSzuVGDcXlLLb+R841FFLw733gGOze76b6LmVhmjgmlFWbgRUE8V/LWaIixFksUm56i0pSliBgjO0CcK5i+yIAVwnffwvgt9I+3QDUKzZXmBqSAxWpoBefNB7/WrYVx0WcHFYrxNm5lbs2reKMAOJZj+DjMydK+0Y9p/u5HjSCauQaqsQ5laahkAvW0jwmToPOLK6dF1EJe+F500Z7UvAOFspdoUpEjJyK5XxFagTFaCLFzCwmssoSR9K5ajMYNQKPjwBhkUHk7DcYGPy1aZBTi3lHqkUtawRnHtGBMw/viBwmS0XcSinpKLRGUBxxCQK+cM87Dh3lhIGqTj3YWnVDagS1hJYDLnF2bnFHTrWkk7jr32dE3r84jSB6ORJEyINpH0HR14rnPCdOaHe0bQpxFg82Bn9tGuTU4izDahE2Z6DYxibPrh5oKpF0DnBHn/WgEQzkIKginXWIj2CwNevBX5sGOfUwmoiLsOUXAyacF9y/WhpXMbNHS5l8Vg/zCOql7ocJcrHennl4B4B4FsGKm9orUYNRi5NLqkUlOrdqPd9KaSL15CMAgFFDMvjSucWnwa4lwnwE4vDlvy6chk+fMQUjFSv+VRstCKqMlgMuKrt3c9rKaDp2WHGL9Jgxp6EulkqZ/Pjt1INGAACLri0tDXYtoTYN+bcmEwbGtxe3XslAoQVBldFRQy6q0fvRBw/DrR89AecUmdk07lxDxVKpy/L6Ui8aQT0Q1oYHS/ioFgRVppZmOdcqHyghjXbcM4uLpVL27wQREgZpk2KN401FUfvoYUWVGWxRQ6Pbas++qcJZj2BwPd6CEFHdmIXqhXoYzGmNoMoMtjr0zNfPcezvtUy5a9PWKglDm4VqDT2hTFM2g03FHzSdUJEpIarNseOGRVpJziCqi8lkA8U9c2Zi4brdlTm544cK2aX2x0wAtCCoOvWgVsbNzCnlpwVnRSaJqzb/+OI7I+1nECGTHCx3VX1OnTISp04ZWdFrKLP8Smsk1zpaEFSZQaYQVJxV3393LFqSM7O4zh6wYQDJWlzrsBEJSUMtJqcbDGhBUGXqzYZdLnGZnpyFZGI5W+2Q0M7i2qGO/FC6RmnqkrjTUNcKBhFS2jRUU9TD29CCoI44tKMVw1tS1S5GTcDqaLQmYhhaI6g1VNZHt9oNDtuQNg3VEfO/cla1i1Az1KtpyKBBFLnVIKgGG9yBPFh8BLpGaeqSuBevrxUMIqSTiWoXQyMQrhEMDrQg0NQljmmousWInbamFIY3a/NfTRGahnoAy1EG2jRUJY4dNwxLN3VVuxh1i5tior5EwS2XnqB9BDVGPdQwLQiqxD3/MRNdB7LVLkbdYprW/4GWA498+V3YtrevYucfN7y4dNyayqMabLjrEQwOlUALgirRkk6iJa0ff6WoVvM7ckwbjhxTpYtrqoJqsHH4mKEAgOkTy58lPxDonkhTl7hLVdaD4q6pZVTO4pMmtOP5q8/B2GFNA1+gEtCCQFOXsEGWdE4zeFHmGgJw8CAy42mvk6YucZLOaUGgqRD1VMfKEgRENIKI5hHRm/b/9oD9HiGiPUT0kLR9MhG9RESriegeIkqXUx6NhjNtbBsAYGiTDrXUVJZ6mKtSrkZwNYD5jLGpAObb31XcBODjiu03AriFMXYYgE4AV5ZZHo0GAHDDh47DXz9zmo6y0VQMbhIa/GKgfEFwEYC77M93AfiAaifG2HwA+8RtZInRcwD8tdDxGk2xNKUSmD5pcERsaAYnzlyVOjCwl3sLoxljW+zPWwGMLuLYkQD2MMZy9veNAAKXaCKiOUS0iIgW7dixo7TSajQaTcwEOYsHEwWjhojoMQCqyOhviV8YY4yIKha+zRi7HcDtADB9+vTBMUtDo9HUPXXgIigsCBhjs4J+I6JtRDSWMbaFiMYC2F7EtXcBGE5ESVsrGA9gUxHHazQaTdXRzmLgQQBX2J+vAPBA1AOZNePnCQCXlHK8RqPR1AKDXwyULwhuAHAeEb0JYJb9HUQ0nYju4DsR0TMA7gNwLhFtJKIL7J++AeA/iWg1LJ/Bb8osj0aj0QwodaAQlDezmDG2C8C5iu2LAFwlfH9XwPFrAcwopwylMqI1je6+XOEdNRqNJoSGcBbXKy990ye/NBqNpiFpWEGQ0jndNRqNBoDONaTRaDQlMVhWH4uCFgQajUbT4GhBoNFoNCVQD9FCHC0INBqNpsHRgkCj0WgaHC0INBqNpgS0s1ij0Wg0dYMWBBqNRtPgaEGg0Wg0ZVAP0UNaEGg0Gk0Z1IOvQAsCjUajaXC0INBoNJoy0KYhjUaj0Qx6tCDQaDSaBkcLAo1GoymBenASc7Qg0Gg0mgZHCwKNRqMpgXpwEnO0INBoNJoS0KYhjUaj0dQNWhBoNBpNg6MFgUaj0TQ4WhBoNBpNg6MFgUaj0TQ4ZQkCIhpBRPOI6E37f3vAfo8Q0R4iekjaficRvUVES+y/E8opj0aj0WiKp1yN4GoA8xljUwHMt7+ruAnAxwN++xpj7AT7b0mZ5dFoNBpNkZQrCC4CcJf9+S4AH1DtxBibD2BfmdfSaDSamqMe5pWVKwhGM8a22J+3Ahhdwjl+QESvEdEtRJQpszwajUYzIGRSVvdpGINfFCQL7UBEjwEYo/jpW+IXxhgjomLn2l0DS4CkAdwO4BsArg8oxxwAcwBgwoQJRV5Go9Fo4uU77zsaBw9vxqyjShn/1hYFBQFjbFbQb0S0jYjGMsa2ENFYANuLubigTfQR0e8AfDVk39thCQtMnz69jiZ3azSawUh7axrfmH1ktYsRC+Wahh4EcIX9+QoADxRzsC08QEQEy7+wrMzyaDQajaZIyhUENwA4j4jeBDDL/g4imk5Ed/CdiOgZAPcBOJeINhLRBfZPfyKipQCWAhgF4Ptllkej0Wg0RVLQNBQGY2wXgHMV2xcBuEr4/q6A488p5/oajUajKR89s1ij0WgaHC0INBqNpsHRgkCj0WgaHC0INBqNpsHRgkCj0WgaHGKDcOFNItoBYH2Jh48CsDPG4tQ6jXS/jXSvQGPdbyPdK1C5+53IGOuQNw5KQVAORLSIMTa92uUYKBrpfhvpXoHGut9Guldg4O9Xm4Y0Go2mwdGCQKPRaBqcRhQEt1e7AANMI91vI90r0Fj320j3Cgzw/Tacj0Cj0Wg0XhpRI9BoNBqNgBYEGo1G0+A0lCAgotlEtJKIVhPR1dUuT7kQ0W+JaDsRLRO2jSCieUT0pv2/3d5ORPRT+95fI6KTqlfy4iGiQ4joCSJaQUTLiehL9vZ6vd8mIlpARK/a9/tde/tkInrJvq97iChtb8/Y31fbv0+qZvlLgYgSRPQKET1kf6/ne11HREuJaAkRLbK3Va0uN4wgIKIEgNsAvBvANACXEdG06paqbO4EMFvadjWA+YyxqQDm298B676n2n9zAPxigMoYFzkAX2GMTQMwE8Dn7fdXr/fbB+AcxtjxAE4AMJuIZgK4EcAtjLHDAHQCuNLe/0oAnfb2W+z9BhtfAvC68L2e7xUAzmaMnSDMF6heXWaMNcQfgNMAzBW+XwPgmmqXK4b7mgRgmfB9JYCx9uexAFban38F4DLVfoPxD9ZqeOc1wv0CaAHwMoBTYc02TdrbnToNYC6A0+zPSXs/qnbZi7jH8bA6v3MAPASA6vVe7XKvAzBK2la1utwwGgGAcQA2CN832tvqjdHMXQt6KwC+snbd3L9tCjgRwEuo4/u1TSVLYK0FPg/AGgB7GGM5exfxnpz7tX/vAjByYEtcFrcC+DoA0/4+EvV7rwDAADxKRIuJaI69rWp1uawVyjS1DWOMEVFdxQcT0RAA9wP4MmNsr7XctUW93S9jLA/gBCIaDuDvAOpjpXQJIroQwHbG2GIiOqva5Rkg3skY20REBwGYR0RviD8OdF1uJI1gE4BDhO/j7W31xjYiGgsA9v/t9vZBf/9ElIIlBP7EGPubvblu75fDGNsD4AlY5pHhRMQHcOI9Ofdr/z4MwK4BLmqpnA7g/US0DsDdsMxDP0F93isAgDG2yf6/HZaQn4Eq1uVGEgQLAUy1IxHSAC4F8GCVy1QJHgRwhf35Cli2dL79E3YEwkwAXYIaWvOQNfT/DYDXGWM3Cz/V6/122JoAiKgZlj/kdVgC4RJ7N/l++XO4BMDjzDYo1zqMsWsYY+MZY5NgtcvHGWOXow7vFQCIqJWIhvLPAM4HsAzVrMvVdpoMsIPmPQBWwbK1fqva5Ynhfv4CYAuALCy74ZWwbKXzAbwJ4DEAI+x9CVbU1BoASwFMr3b5i7zXd8Kyq74GYIn99546vt/jALxi3+8yAN+2t08BsADAagD3AcjY25vs76vt36dU+x5KvO+zADxUz/dq39er9t9y3hdVsy7rFBMajUbT4DSSaUij0Wg0CrQg0Gg0mgZHCwKNRqNpcLQg0Gg0mgZHCwKNRqNpcLQg0Gg0mgZHCwKNRqNpcP4/eiiIzYj4dh8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nv0A7HJFPTAD"
      },
      "source": [
        "means1 = []\n",
        "means1a = []\n",
        "\n",
        "for k in range(10):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "        # plt.plot(l_pred[0][0, :, i])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means1.append(np.mean(np.mean(l_pred)))\n",
        "    means1a.append(np.mean(np.mean(np.abs(l_pred))))\n",
        "\n",
        "means2 = []\n",
        "means2a = []\n",
        "\n",
        "for k in range(10, 30):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "    #     plt.plot(l_pred[0, i, :])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means2.append(np.mean(np.mean(l_pred)))\n",
        "    means2a.append(np.mean(np.mean(np.abs(l_pred))))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvl4w8AcPho3"
      },
      "source": [
        ""
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDjwIPy5RDRf",
        "outputId": "289989e8-d459-44f5-8f8a-ef6ed87214da"
      },
      "source": [
        "print(\"Mean energy on recurrent preactivation (LSTM) on sigmoid activation function after training\")\n",
        "print(np.mean(means1), np.mean(means2), \"(ME)\")\n",
        "print(np.mean(means1a), np.mean(means2a), \"(MAE)\")\n",
        "print(100*np.abs(np.mean(means1)-np.mean(means2))/np.mean(means1), \"(Difference ratio, percentage %)\")\n",
        "print(100*np.abs(np.mean(means1a)-np.mean(means2a))/np.mean(means1a), \"(Difference abs ratio, percentage %)\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean energy on recurrent preactivation (LSTM) on sigmoid activation function after training\n",
            "0.0011250929 0.001110463 (ME)\n",
            "0.021287879 0.020823175 (MAE)\n",
            "1.3003190861706493 (Difference ratio, percentage %)\n",
            "2.182950627635711 (Difference abs ratio, percentage %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFbo2uU3hQfJ"
      },
      "source": [
        "## Lesioning the network\n",
        "\n",
        "In this section, we've lesioned the RNN via adding a gaussian noise with mean=0 and STD=0.1 to all weights of the network as a simulation of simple lesioning.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_tEwkohTzn"
      },
      "source": [
        "Net2 = Net1\n",
        "w = Net2.model.get_weights()\n",
        "for i in range(2, len(w)):\n",
        "    w[i] += (np.random.randn(*w[i].shape))*(np.std(w[i])*2)\n",
        "Net2.model.set_weights(w)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfYNWruWnms-",
        "outputId": "a9064584-de0d-4aa1-bb41-6ab61bbd6b25"
      },
      "source": [
        "# Single epoch for test\n",
        "history = Net2.model.fit(\n",
        "    x=X, y=Y,\n",
        "    epochs=1,\n",
        "    batch_size=5,\n",
        "    validation_split=0.0,\n",
        "    verbose=1,\n",
        "    shuffle=True\n",
        ")\n",
        "# history2 = L1.fit(x=X, y=Y, epochs=1, batch_size=5, validation_split=0.0, verbose=1, shuffle=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 1s 346ms/step - loss: 0.2976\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nFimIkWRO0g"
      },
      "source": [
        "means1 = []\n",
        "means1a = []\n",
        "\n",
        "for k in range(10):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net2.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net2.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "        # plt.plot(l_pred[0][0, :, i])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means1.append(np.mean(np.mean(l_pred)))\n",
        "    means1a.append(np.mean(np.mean(np.abs(l_pred))))"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrNYpR5ricJz"
      },
      "source": [
        "means2 = []\n",
        "means2a = []\n",
        "\n",
        "for k in range(10, 30):\n",
        "    l, r = k, k+1\n",
        "    l_pred = Net2.getPreactivation(Xn[l:r, :, :])\n",
        "    y_pred = Net2.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "    # for i in range(7):\n",
        "    #     plt.plot(l_pred[0, i, :])\n",
        "    # for i in range(10):\n",
        "    # plt.plot(y_pred[0, :, 6])\n",
        "    # for i in range(0, 100, 10):\n",
        "    #     print(Yn[l:r, i, :])\n",
        "    means2.append(np.mean(np.mean(l_pred)))\n",
        "    means2a.append(np.mean(np.mean(np.abs(l_pred))))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZqFPv4mifEc",
        "outputId": "f5dcb029-2903-49f6-be6a-d7afe3f7197d"
      },
      "source": [
        "print(\"Mean energy on recurrent preactivation (LSTM) on sigmoid activation function after lesioning\")\n",
        "print(np.mean(means1), np.mean(means2), \"(ME)\")\n",
        "print(np.mean(means1a), np.mean(means2a), \"(MAE)\")\n",
        "print(100*np.abs(np.mean(means1)-np.mean(means2))/np.mean(means1), \"(Difference ratio, percentage %)\")\n",
        "print(100*np.abs(np.mean(means1a)-np.mean(means2a))/np.mean(means1a), \"(Difference abs ratio, percentage %)\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean energy on recurrent preactivation (LSTM) on sigmoid activation function after lesioning\n",
            "0.002859047 0.0029484958 (ME)\n",
            "0.089354925 0.08714984 (MAE)\n",
            "3.128625703641504 (Difference ratio, percentage %)\n",
            "2.467778119180206 (Difference abs ratio, percentage %)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPA9gwQbpDkH"
      },
      "source": [
        ""
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Adv7TqW_lAO2",
        "outputId": "25d7db01-2c38-493d-81c5-cf29c3b46410"
      },
      "source": [
        "D1 = []\n",
        "D2 = []\n",
        "\n",
        "for j in range(20):\n",
        "    Net1 = PredictiveNet()\n",
        "    # a = model.predict(Xn[1:2, :, :])\n",
        "    Net1.model.compile(\n",
        "      loss=Net1.EnergyCostLoss,\n",
        "      optimizer=tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "    )\n",
        "\n",
        "    # Single epoch for test\n",
        "    history = Net1.model.fit(\n",
        "        x=X, y=Y,\n",
        "        epochs=20,\n",
        "        batch_size=5,\n",
        "        validation_split=0.0,\n",
        "        verbose=1,\n",
        "        shuffle=True\n",
        "    )\n",
        "    # history2 = L1.fit(x=X, y=Y, epochs=1, batch_size=5, validation_split=0.0, verbose=1, shuffle=True)\n",
        "\n",
        "    means1 = []\n",
        "    means1a = []\n",
        "\n",
        "    for k in range(10):\n",
        "        l, r = k, k+1\n",
        "        l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "        y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "        # for i in range(7):\n",
        "            # plt.plot(l_pred[0][0, :, i])\n",
        "        # for i in range(10):\n",
        "        # plt.plot(y_pred[0, :, 6])\n",
        "        # for i in range(0, 100, 10):\n",
        "        #     print(Yn[l:r, i, :])\n",
        "        means1.append(np.mean(np.mean(l_pred)))\n",
        "        means1a.append(np.mean(np.mean(np.abs(l_pred))))\n",
        "\n",
        "    means2 = []\n",
        "    means2a = []\n",
        "\n",
        "    for k in range(10, 30):\n",
        "        l, r = k, k+1\n",
        "        l_pred = Net1.getPreactivation(Xn[l:r, :, :])\n",
        "        y_pred = Net1.model.predict(Xn[l:r, :, :])\n",
        "\n",
        "        # for i in range(7):\n",
        "        #     plt.plot(l_pred[0, i, :])\n",
        "        # for i in range(10):\n",
        "        # plt.plot(y_pred[0, :, 6])\n",
        "        # for i in range(0, 100, 10):\n",
        "        #     print(Yn[l:r, i, :])\n",
        "        means2.append(np.mean(np.mean(l_pred)))\n",
        "        means2a.append(np.mean(np.mean(np.abs(l_pred))))\n",
        "    \n",
        "    D1.append(np.mean(means1))\n",
        "    D2.append(np.mean(means2))\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 304ms/step - loss: 0.9895\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.4219\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.2929\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.2513\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.1389\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0755\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0884\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0878\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.0627\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0457\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0322\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0348\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0351\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0283\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0196\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0189\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0205\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0173\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0145\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0118\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 323ms/step - loss: 0.9314\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.3737\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.3269\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.2299\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.1056\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0979\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.1065\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0804\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0509\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0375\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0417\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0433\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0321\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0236\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0217\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0220\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0214\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0151\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0139\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0135\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 342ms/step - loss: 1.1775\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.4196\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.3549\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.2985\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.1177\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0941\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.1128\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0945\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0636\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0380\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0412\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0458\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0377\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0289\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0195\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0240\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0239\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0183\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0139\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0143\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 338ms/step - loss: 0.9449\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.3932\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.2997\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.2136\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0967\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.1060\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1029\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0637\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0403\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0515\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0496\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0360\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0220\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0274\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0274\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0200\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0152\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0180\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0161\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0124\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 304ms/step - loss: 1.1736\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.3961\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.3742\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.2461\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.1111\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.1110\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.1136\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.0818\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0413\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0427\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0453\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0449\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0317\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0204\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0213\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0234\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0212\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0147\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0149\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0149\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 342ms/step - loss: 1.0245\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.4216\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.3555\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.2718\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.1096\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 318ms/step - loss: 0.1035\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.1169\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0808\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0467\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0427\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0494\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0460\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0325\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0229\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0225\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0245\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0204\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0143\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0143\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0155\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 340ms/step - loss: 1.0852\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.3696\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.3525\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.2255\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0953\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1318\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.1044\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0542\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0467\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0551\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0462\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0301\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0255\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0304\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0258\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0181\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0192\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0179\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0126\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0134\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 313ms/step - loss: 0.9513\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.4563\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.2739\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.2517\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.1121\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0821\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0993\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0822\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0498\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0372\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0423\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0417\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0301\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0218\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0211\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0234\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0197\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0134\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0142\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0145\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 343ms/step - loss: 0.9596\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.4248\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.3224\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.2676\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.1354\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0820\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0959\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0907\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0649\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0403\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0325\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0381\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0370\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0313\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0217\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0184\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0180\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0189\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0148\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0114\n",
            "WARNING:tensorflow:Layer lstm_10 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 349ms/step - loss: 0.9895\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.4183\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.3205\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.2648\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1410\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0789\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1023\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0822\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0646\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0393\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0359\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 301ms/step - loss: 0.0424\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0381\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0279\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0213\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0190\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0227\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0185\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0150\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.0130\n",
            "WARNING:tensorflow:Layer lstm_11 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 313ms/step - loss: 0.9658\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.3845\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.4342\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.2529\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.1159\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.1212\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1175\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0762\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0424\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0461\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0491\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0444\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0327\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0205\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0246\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0249\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0216\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0155\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0149\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0151\n",
            "WARNING:tensorflow:Layer lstm_12 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 349ms/step - loss: 1.0131\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.4617\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.2862\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.2492\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.1352\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0740\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.1028\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0833\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0658\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0391\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0397\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0415\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0351\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0250\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0209\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0225\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0213\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0174\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0134\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0130\n",
            "WARNING:tensorflow:Layer lstm_13 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 331ms/step - loss: 0.9483\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.3871\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.3248\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.2413\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.1252\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0757\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0928\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0816\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0614\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0337\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0362\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0394\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0356\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0252\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0188\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0213\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0212\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0173\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0142\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0137\n",
            "WARNING:tensorflow:Layer lstm_14 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 309ms/step - loss: 1.1263\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.3800\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.3537\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.2798\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1157\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0900\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1070\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0885\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0496\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0385\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0420\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0442\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0359\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0235\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0203\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0233\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0215\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0153\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0141\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0149\n",
            "WARNING:tensorflow:Layer lstm_15 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 341ms/step - loss: 1.2333\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.4413\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.3895\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.2844\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.1218\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1035\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1196\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0976\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0565\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0378\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0431\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0450\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0364\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0231\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.0219\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0253\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0226\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0169\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0149\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0159\n",
            "WARNING:tensorflow:Layer lstm_16 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 336ms/step - loss: 0.9698\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.4522\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.3024\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.2391\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.1211\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0771\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0958\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0829\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0549\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0359\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0379\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0412\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0335\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0246\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0183\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0218\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0201\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0158\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0135\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0134\n",
            "WARNING:tensorflow:Layer lstm_17 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 341ms/step - loss: 0.8621\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.3995\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.2410\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.2174\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.1238\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 303ms/step - loss: 0.0740\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0788\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0775\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0585\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0374\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0342\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0394\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0326\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.0273\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0191\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0196\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0191\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0170\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0131\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 323ms/step - loss: 0.0149\n",
            "WARNING:tensorflow:Layer lstm_18 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 3s 308ms/step - loss: 1.0226\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.4006\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.3453\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 308ms/step - loss: 0.2749\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.1160\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0929\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.1119\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0934\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0580\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0390\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0438\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0465\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 302ms/step - loss: 0.0381\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0273\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0226\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0240\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0235\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0172\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0150\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.0156\n",
            "WARNING:tensorflow:Layer lstm_19 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 335ms/step - loss: 1.0888\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.4185\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.3428\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.2512\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.1078\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.1079\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.1131\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0842\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0481\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0405\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.0459\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0434\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0335\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0220\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.0223\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 307ms/step - loss: 0.0234\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0206\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0147\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0151\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0144\n",
            "WARNING:tensorflow:Layer lstm_20 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "Epoch 1/20\n",
            "2/2 [==============================] - 2s 331ms/step - loss: 0.8546\n",
            "Epoch 2/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.3732\n",
            "Epoch 3/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.3124\n",
            "Epoch 4/20\n",
            "2/2 [==============================] - 1s 305ms/step - loss: 0.2536\n",
            "Epoch 5/20\n",
            "2/2 [==============================] - 1s 306ms/step - loss: 0.1315\n",
            "Epoch 6/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0801\n",
            "Epoch 7/20\n",
            "2/2 [==============================] - 1s 315ms/step - loss: 0.0974\n",
            "Epoch 8/20\n",
            "2/2 [==============================] - 1s 311ms/step - loss: 0.0911\n",
            "Epoch 9/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0669\n",
            "Epoch 10/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0448\n",
            "Epoch 11/20\n",
            "2/2 [==============================] - 1s 310ms/step - loss: 0.0323\n",
            "Epoch 12/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0348\n",
            "Epoch 13/20\n",
            "2/2 [==============================] - 1s 313ms/step - loss: 0.0357\n",
            "Epoch 14/20\n",
            "2/2 [==============================] - 1s 316ms/step - loss: 0.0302\n",
            "Epoch 15/20\n",
            "2/2 [==============================] - 1s 314ms/step - loss: 0.0220\n",
            "Epoch 16/20\n",
            "2/2 [==============================] - 1s 312ms/step - loss: 0.0188\n",
            "Epoch 17/20\n",
            "2/2 [==============================] - 1s 319ms/step - loss: 0.0198\n",
            "Epoch 18/20\n",
            "2/2 [==============================] - 1s 317ms/step - loss: 0.0186\n",
            "Epoch 19/20\n",
            "2/2 [==============================] - 1s 309ms/step - loss: 0.0166\n",
            "Epoch 20/20\n",
            "2/2 [==============================] - 1s 304ms/step - loss: 0.0119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "y28lM35clkCI",
        "outputId": "d56c6d49-000d-4d00-a7cd-2b151d682e14"
      },
      "source": [
        "plt.hist(D1)\n",
        "plt.hist(D2)\n",
        "plt.title(\"MAE of preactivation for two case states.\")\n",
        "print(\"Mean preactivation energy of pred: \", np.mean(D1), \" unpred: \", np.mean(D2))\n",
        "print(\"Mean difference ratio percent (MDR%) = \", 100*(np.mean(D1) - np.mean(D2)) / np.mean(D2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean preactivation energy of pred:  -0.00070752884  unpred:  -0.00065304653\n",
            "Mean difference ratio percent (MDR%) =  8.342791775638558\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAEICAYAAAC3Y/QeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAanUlEQVR4nO3de7QcZZ3u8e9DEojcwiV7MOTCRi7OgBcuW8ARxwwXDZdDnCWOgCJBPBFHzuAZ5jggLgaYcY7gGeUoLjEDLu4CIjoR8WDmQGCYkUACAeV2CBBNYpSQQEJU0MDv/FHvJpWme3ftvat37/g+n7Vq7bq8/db7VvV+urqqulsRgZmZ5WWLbjfAzMxGnsPfzCxDDn8zsww5/M3MMuTwNzPLkMPfzCxDDv/NnKRdJN0t6UVJ/9zt9lQlaZqk9ZLGdKDuD0v6Ud31pro/KelXqe07d2IdZiPB4T8IkpZK+p2kiQ3zH5QUknob5p+f5h/cMH+WpFdSgJSHXYfQrNnAc8D2EXHWEB4/ItK2O6J/OiJ+HhHbRsQrw6y3N23jsaW6r4uI9w6n3hbrGgd8CXhvavvqGurcZLvkpNm+q/CYbLdX3Rz+g/cMcGL/hKS3Als3FpIk4KPAmvS30Y9TgJSHXwyhPbsBj0YNn9YbzD9hpnYBxgOPDPaBKvj/zUaPiPBQcQCWAp8D7i/N+1/AuUAAvaX5fwb8FvgwsBrYsrRsFnDPINb7p8D9wNr090/T/CuB3wO/A9YDRzR57JXAZcA84EXgLmC30vIAPgU8CTyT5h0LLAZeAP4TeFup/NnAU6muR4G/aFjffwUeKy0/ALgGeDVtj/XAZ4DetO6xwIeAhQ31/Hdgbho/BngQWAcsA84vlft5qmd9Gt7ZuH1bbb+0bD7wD8B/pDb/CJjYZDvuDfy6tK47Ktb9+VT3b4E9G+pstl2uAs5Kyyf37580vQfFwcQWpW29JM2bC+w6wHPo0LQvX0jbcFaFbTseuJbi+ftC6t8uadkE4ApgJbAC+EdgTIt1HwQsTOv4FfClAfbdHsAdaZ3PAdcBO7TaXmn+IaW+PQRMb/hfezrt22eAD3c7R0bL0PUGbE4DRfgfATwB/AkwBlhOcfTdGP5XADcB49IT+QOlZbOoGP7ATsDzwMkUQXlimt45Lb8S+McBHn9leuL/GbAV8L/ZNBiD4oVhJ+ANwP7As8DBqX+npH5vlcp/ENiV4l3jhygCcVJp2QrgHYCAPUkvNP3brrTeXjaG/9apjXuVlt8PnJDGpwNvTet8WwqQ9zfW02z7Vth+8ylezPZO/Z8PfKHFttxkXRXr/jmwb1o+rtVzqjT9MeD7afyk1LYbS8v+NY0fRhGOB6T9+lXg7hbt3i1t3xMpno87A/tV2LafAL6f9s8Y4ECK04sA3wW+AWwD/BFwH/CJFuv/MXByGt8WOGSAfbcncGTqUw9wN3DJANtrMsX/19GpD0em6Z7UtnXAm1PZScC+3c6R0TJ0vQGb08DG8P8c8D+BGRTBOZZS+Kd/lnWlf6Jv9P/TpulZwAaKI5X+4akW6zwZuK9h3o/ZeOR2Je3D/4bS9LbAK8DUNB3AYaXlXwf+oaGOJ4D3tKh/MTAzjd8OnDnQtitNb/KPT3GEeV4a34sirLZuUdclwJeb1VPavv3h3277zQc+V1r2V8D/abHexjZXqfvCKs+p0vQeFC8gW1C8Y/sEsDwtuwr4mzR+BXBxw379PaUDkNKyc4DvVnyOl7ftx2h455fm7wK8DLyhNO9E4M4Wdd4NXEDDO6pm+67JY98PPDjA9vo74JqGx9xOcdCyDcX/1gfKbfVQDD4HOTTXUByVzQKubrL8LyjC/bY0fR1wlKSeUpl7I2KH0rBHi3XtCvysYd7PKI54qlrWPxIR6ylOE+zabDnFUeJZkl7oH4Cp/eUlfVTS4tKytwD9F8CnUhypDsX1bLyWchLwvYj4TVrnwZLulLRK0lrg9NI626my/X5ZGv8NRZDWVfcyBiEinqJ4N7Uf8G7gVuAXkt4MvIfitN3r1p3262qaPy9a7pc22/YaiiC9QdIvJF2cLnrvRvEOYmXpefANincAzZxG8c7qcUn3Szq2Vf/T3Ws3SFohaR3FQcFA+3o34IMNz9dDKd6N/pri3enpqa0/kPTHA9SVFYf/EETEzyjOHx4N3NKkyCkUAfJzSb8Evk3xz3LSEFb3C4oneNk0itMrVU3tH5G0LcXpivLF5SiNLwM+3/DCtHVEfEvSbsC/AGdQnNrYAfgpxSme/se2ehGLFvP7zQN6JO1H8SJwfWnZ9RTntKdGxASKI+L+dbart47tN5y627Wv2fK7gOMprhOtSNOnADtSvNN63bolbUNxOqdZvwbaLy23bUT8PiIuiIh9KK5tHEtx88IyiiP/iaXnyPYRsW/TDkY8GREnUrw4XATcnNrbrO//lOa/NSK2Bz7Cxn1Nk8csozjyLz9ft4mIL6R13x4RR1Kc8nmc4vlrOPyH4zSK0yW/Ls+UNBk4nOIfZb80vJ3iSd/srp92bgP2lnSSpLGSPgTsQ3FEWNXRkg6VtCXFxc17I6LVEem/AKenI0JJ2kbSMZK2o3gbHcAqAEmnUhz597sc+FtJB6bH7pleMKA4l/ymVg2MiN9TvEh+keLFaV5p8XbAmoh4SdJBbPoiuoriImCruuvYfq3UUXez7XIXxQvs3Wl6fpq+JzbeGvst4FRJ+0naiiI0F0TE0ibruA44QtJfpnbunF5kYYBtK+nPJb01fRZjHcVppVcjYiXFhfF/lrS9pC0k7SHpPc06KOkjknoi4lWK0zBQ7LNm+247iou5a9P/0v9os72uBf6LpPdJGiNpvKTpkqakdxEz0wvNy6neV5u1MUvdPu+0OQ00nG8szX/tnD/F3TCLmpTZleKf5y0Up4teYeNdDv3DO1qs91BgEcUdJYuAQ0vLrqT9Of/+u33WUwTK7qXlwevvQplBccH1BYq7Ob4NbJeWfZ7itNFzFPe83wV8vPTY0ymuEayneFewf5o/k+Li5wvA39L8XP2707yvNbTneIpTHC9SBOulwLWl5RdSBMkLFHd+zGLTi9oDbb/5De3f5LEN7WjW5sp1t6hzk+2S5r05reeUND2B4jTi3zU89nSK0zlr0naZMsB63g0sYONdPf11t9y2FO/AnqA4DfUr4CtsvN4xgeL60PLU9wdJF+ibrPtaipsI1lPcJvv+Afbdvmk7rqd4l3MW6ZrHANvrYIrn4ZpU1w8o3oFNSvPXpvLzgX1K22N9tzOlm4PShrA/UJKupPjn+Vy322Jmo4dP+5iZZcjhb2aWIZ/2MTPLkI/8zcwy1LUv8po4cWL09vZ2a/VmZpulRYsWPRcRPe1LDqxr4d/b28vChQu7tXozs82SpMZPlQ+JT/uYmWXI4W9mliGHv5lZhhz+ZmYZcvibmWXI4W9mlqHK4Z++LvVBSa/7ulpJW0m6UdISSQsk9dbZSDMzq9dgjvzPpPhh7mZOA56PiD2BL1N8d72ZmY1SlcJf0hTgGIof62hmJsXviwLcDBwuSS3KmplZl1X9hO8lwGcofmWnmcmk3yqNiA3pt0B3pvjBj9dImg3MBpg2bdpQ2ms5OX9C11bd+9L1LP3CMSO/4m71+fy13VmvdU3bI//0Y8vPRsSi4a4sIuZERF9E9PX0DPurKczMbIiqnPZ5F3CcpKXADcBhkq5tKLOC9CPhksZS/MTb6hrbaWZmNWob/hFxTkRMiYhe4ATgjoj4SEOxucApafz4VMY/FGBmNkoN+Vs9JV0ILIyIucAVwDWSllD8iPIJNbXPzMw6YFDhHxHzgflp/LzS/JeAD9bZMDMz6xx/wtfMLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8tQlR9wHy/pPkkPSXpE0gVNysyStErS4jR8vDPNNTOzOlT5Ja+XgcMiYr2kccA9kn4YEfc2lLsxIs6ov4lmZla3tuGffoh9fZoclwb/OLuZ2Was0jl/SWMkLQaeBeZFxIImxT4g6WFJN0uaWmsrzcysVpXCPyJeiYj9gCnAQZLe0lDk+0BvRLwNmAdc1aweSbMlLZS0cNWqVcNpt5mZDcOg7vaJiBeAO4EZDfNXR8TLafJy4MAWj58TEX0R0dfT0zOU9pqZWQ2q3O3TI2mHNP4G4Ejg8YYyk0qTxwGP1dlIMzOrV5W7fSYBV0kaQ/FicVNE3CrpQmBhRMwF/lrSccAGYA0wq1MNNjOz4atyt8/DwP5N5p9XGj8HOKfeppmZWaf4E75mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhmq8hu+4yXdJ+khSY9IuqBJma0k3ShpiaQFkno70VgzM6tHlSP/l4HDIuLtwH7ADEmHNJQ5DXg+IvYEvgxcVG8zzcysTm3DPwrr0+S4NERDsZnAVWn8ZuBwSaqtlWZmVqu2P+AOIGkMsAjYE/haRCxoKDIZWAYQERskrQV2Bp5rqGc2MBtg2rRpw2u5dV3v2T/oaP1Lx3e0eis7f0IX1722e+vOWKULvhHxSkTsB0wBDpL0lqGsLCLmRERfRPT19PQMpQozM6vBoO72iYgXgDuBGQ2LVgBTASSNBSYAq+tooJmZ1a/K3T49knZI428AjgQebyg2FzgljR8P3BERjdcFzMxslKhyzn8ScFU6778FcFNE3CrpQmBhRMwFrgCukbQEWAOc0LEWm5nZsLUN/4h4GNi/yfzzSuMvAR+st2lmZtYp/oSvmVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGqvyG71RJd0p6VNIjks5sUma6pLWSFqfhvGZ1mZnZ6FDlN3w3AGdFxAOStgMWSZoXEY82lPv3iDi2/iaamVnd2h75R8TKiHggjb8IPAZM7nTDzMyscwZ1zl9SL8WPuS9osvidkh6S9ENJ+7Z4/GxJCyUtXLVq1aAba2Zm9agc/pK2Bb4DfDoi1jUsfgDYLSLeDnwV+F6zOiJiTkT0RURfT0/PUNtsZmbDVCn8JY2jCP7rIuKWxuURsS4i1qfx24BxkibW2lIzM6tNlbt9BFwBPBYRX2pR5o2pHJIOSvWurrOhZmZWnyp3+7wLOBn4iaTFad5ngWkAEXEZcDzwSUkbgN8CJ0REdKC9ZmZWg7bhHxH3AGpT5lLg0roaZWZmneVP+JqZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZcjhb2aWIYe/mVmGHP5mZhly+JuZZajKb/hOlXSnpEclPSLpzCZlJOkrkpZIeljSAZ1prpmZ1aHKb/huAM6KiAckbQcskjQvIh4tlTkK2CsNBwNfT3/NzGwUanvkHxErI+KBNP4i8BgwuaHYTODqKNwL7CBpUu2tNTOzWlQ58n+NpF5gf2BBw6LJwLLS9PI0b2XD42cDswGmTZs2uJZa95w/oenspeNHuB0jaOn4k+D8brciEy2eX51f79rurHeUqHzBV9K2wHeAT0fEuqGsLCLmRERfRPT19PQMpQozM6tBpfCXNI4i+K+LiFuaFFkBTC1NT0nzzMxsFKpyt4+AK4DHIuJLLYrNBT6a7vo5BFgbEStblDUzsy6rcs7/XcDJwE8kLU7zPgtMA4iIy4DbgKOBJcBvgFPrb6qZmdWlbfhHxD2A2pQJ4FN1NcrMzDrLn/A1M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8tQld/w/aakZyX9tMXy6ZLWSlqchvPqb6aZmdWpym/4XglcClw9QJl/j4hja2mRmZl1XNsj/4i4G1gzAm0xM7MRUtc5/3dKekjSDyXt26qQpNmSFkpauGrVqppWbWZmg1VH+D8A7BYRbwe+CnyvVcGImBMRfRHR19PTU8OqzcxsKIYd/hGxLiLWp/HbgHGSJg67ZWZm1jHDDn9Jb5SkNH5QqnP1cOs1M7POaXu3j6RvAdOBiZKWA38PjAOIiMuA44FPStoA/BY4ISKiYy02M7Nhaxv+EXFim+WXUtwKamZmmwl/wtfMLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLENtw1/SNyU9K+mnLZZL0lckLZH0sKQD6m+mmZnVqcqR/5XAjAGWHwXslYbZwNeH3ywzM+uktuEfEXcDawYoMhO4Ogr3AjtImlRXA83MrH5tf8C9gsnAstL08jRvZWNBSbMp3h0wbdq0oa/x/AlDf+ww9b50fVfWu3T8SV1Zr9kfrC7mCOev7d66kxG94BsRcyKiLyL6enp6RnLVZmZWUkf4rwCmlqanpHlmZjZK1RH+c4GPprt+DgHWRsTrTvmYmdno0facv6RvAdOBiZKWA38PjAOIiMuA24CjgSXAb4BTO9VYMzOrR9vwj4gT2ywP4FO1tcjMzDrOn/A1M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8uQw9/MLEMOfzOzDDn8zcwy5PA3M8tQpfCXNEPSE5KWSDq7yfJZklZJWpyGj9ffVDMzq0uV3/AdA3wNOBJYDtwvaW5EPNpQ9MaIOKMDbTQzs5pVOfI/CFgSEU9HxO+AG4CZnW2WmZl1UpXwnwwsK00vT/MafUDSw5JuljS1WUWSZktaKGnhqlWrhtBcMzOrQ10XfL8P9EbE24B5wFXNCkXEnIjoi4i+np6emlZtZmaDVSX8VwDlI/kpad5rImJ1RLycJi8HDqyneWZm1glVwv9+YC9Ju0vaEjgBmFsuIGlSafI44LH6mmhmZnVre7dPRGyQdAZwOzAG+GZEPCLpQmBhRMwF/lrSccAGYA0wq4NtNjOzYWob/gARcRtwW8O880rj5wDn1Ns0MzPrFH/C18wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQw5/M7MMOfzNzDLk8Dczy5DD38wsQ5XCX9IMSU9IWiLp7CbLt5J0Y1q+QFJv3Q01M7P6tA1/SWOArwFHAfsAJ0rap6HYacDzEbEn8GXgorobamZm9aly5H8QsCQino6I3wE3ADMbyswErkrjNwOHS1J9zTQzszpV+QH3ycCy0vRy4OBWZSJig6S1wM7Ac+VCkmYDs9PkeklPDKXRA5jYuM76HdvZ6lto80o6Av0eldzv/Pxh9P2CQR8bl/u9Wx1NqBL+tYmIOcCcTtUvaWFE9HWq/tHK/c5Lrv2GfPveiX5XOe2zAphamp6S5jUtI2ksMAFYXUcDzcysflXC/35gL0m7S9oSOAGY21BmLnBKGj8euCMior5mmplZndqe9knn8M8AbgfGAN+MiEckXQgsjIi5wBXANZKWAGsoXiC6oWOnlEY59zsvufYb8u177f2WD9DNzPLjT/iamWXI4W9mlqHNIvwl7SRpnqQn098dW5Q7JZV5UtIppfkHSvpJ+vqJr5Q/gCbpv0l6XNIjki4eif5U1cl+p+VnSQpJEzvdl8HoVL8lfTHt64clfVfSDiPVp4EM5+tTJJ2T5j8h6X1V6xwN6u63pKmS7pT0aPp/PnPkelNdJ/Z3WjZG0oOSbq3UkIgY9QNwMXB2Gj8buKhJmZ2Ap9PfHdP4jmnZfcAhFJ+V+iFwVJr/58C/AVul6T/qdl9Hot9p2VSKi/g/AyZ2u68jtL/fC4xN4xc1q7cLfR0DPAW8CdgSeAjYp6HMXwGXpfETgBvT+D6p/FbA7qmeMVXq7PbQoX5PAg5IZbYD/l8O/S497m+A64Fbq7RlszjyZ9Ovj7gKeH+TMu8D5kXEmoh4HpgHzJA0Cdg+Iu6NYgtdXXr8J4EvRMTLABHxbCc7MQSd6jcU38H0GWA0XvHvSL8j4kcRsSE9/l6Kz6x023C+PmUmcENEvBwRzwBLUn1V6uy22vsdESsj4gGAiHgReIzi2wdGk07sbyRNAY4BLq/akM0l/HeJiJVp/JfALk3KNPsaislpWN5kPsDewLvTW6u7JL2j3mYPW0f6LWkmsCIiHqq9xfXo1P4u+xjFu4Jua9WPpmXSi1f/16cMtA3a1dltnej3a9Kpkv2BBTW2uQ6d6vclFAdzr1ZtyIh+vcNAJP0b8MYmi84tT0RESKrraHUsxWmDQ4B3ADdJelM6YhwRI91vSVsDn6U4BdI1Xdrf/es+F9gAXFdnvTY6SNoW+A7w6YhY1+32dJqkY4FnI2KRpOlVHzdqwj8ijmi1TNKvJE2KiJXpbX2z0zMrgOml6SnA/DR/SsP8/q+nWA7cksL+PkmvUnyB0qqh9mOwutDvPSjOFz6UroNOAR6QdFBE/HIYXRmULu1vJM2i+Ha+w0fyRX4Ag/n6lOXa9OtTBnpsuzq7rSP9ljSOIvivi4hbOtP0YelEv48DjpN0NDAe2F7StRHxkQFb0u0LIBUvknyRTS8AXtykzE7AMxQX/3ZM4zulZY0XAI9O808HLkzje1O8pVK3+9vpfjc8fimj74Jvp/b3DOBRoKfbfSz1YyzFxerd2XgBcN+GMp9i0wuAN6Xxfdn0AuDTFBcU29bZ7aFD/RbFNZ5Lut2/kex3w2OnU/GCb9c3RsUNtjPwf4EnKe7O6f8n7wMuL5X7GMVFkCXAqaX5fcBPKa6OX8rGTzZvCVyblj0AHNbtvo5EvxvWsZTRF/6d2t9LKF7gF6fhsm73NbXraIo7U54Czk3zLgSOS+PjgW+n9t8HvKn02HPT455g07u5XlfnaBvq7jdwKMUNDA+X9vHrDni6PXRif5eWT6di+PvrHczMMrS53O1jZmY1cvibmWXI4W9mliGHv5lZhhz+ZmYZcvibmWXI4W9mlqH/DzaKiK8IJOxoAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdiCJe4olvul",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941f81e5-a6f5-4d3a-b528-54cb11634161"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[-0.0018898852,\n",
              " 0.00094540435,\n",
              " 0.0018315583,\n",
              " -0.0058015897,\n",
              " 5.3499483e-05,\n",
              " -0.0012660333,\n",
              " -0.002901127,\n",
              " -0.0011428918,\n",
              " -0.004327598,\n",
              " 0.00032814668,\n",
              " 0.001982758,\n",
              " -0.001639893,\n",
              " 0.00088318705,\n",
              " 0.00026200723,\n",
              " 0.0013052907,\n",
              " -0.0025903978,\n",
              " 0.00026184059,\n",
              " 0.003346958,\n",
              " -0.0023560063,\n",
              " -0.0014358046]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2R5EUZARt9W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}